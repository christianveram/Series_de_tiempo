[["index.html", "Temperatura histórica en la ciudad de Bogotá. Capítulo: 1 Introducción", " Temperatura histórica en la ciudad de Bogotá. Christian Vera, Yuli Deaquiz y Juan Rodríguez 12/04/2025 Capítulo: 1 Introducción La base de datos de Meteostat es una fuente robusta y accesible de información meteorológica histórica, que abarca variables como temperatura, precipitación, humedad, presión atmosférica y velocidad del viento, recopiladas desde estaciones meteorológicas distribuidas a nivel global. Esta plataforma es una herramienta importante para la investigación climática y ambiental, tiene cobertura temporal desde inicios del siglo XX y tiene actualización continua con datos diarios y horarios. Además, esta base de datos integra fuentes oficiales como servicios meteorológicos nacionales, redes de observación internacionales y datos satelitales, lo cual garantiza un alto nivel de confiabilidad y precisión en la generación de modelos predictivos y generación de escenarios de cambio climático[1]. Por lo que, el análisis y pronóstico de datos meteorológicos es una herramienta clave para diversos sectores productivos y sociales, al permitir anticipar condiciones ambientales que impactan directamente en la operación, sostenibilidad y toma de decisiones[2]. Un ejemplo de ello se da en el sector agrícola, donde el uso de datos meteorológicos permite optimizar épocas de siembra, uso adecuado del agua y zonas aptas para el establecimiento de cultivos. De acuerdo con [3], el cambio climático afecta el rendimiento agrícola, por lo que integrar esta información a los sistemas de decisión puede mejorar la producción. Asimismo, [4] muestran cómo los modelos de predicción basados en datos meteorológicos mejoran la precisión del pronóstico de rendimiento de cultivos, permitiendo una planificación más eficiente. En el ámbito urbano, el análisis climático apoya la planificación de infraestructuras y ciudades más adaptadas al calentamiento global. Estudios han demostrado que las proyecciones meteorológicas, combinadas con datos históricos, permiten modelar el impacto y mejorar el diseño urbano para enfrentar eventos extremos [5]. Ciudades que integran esta información pueden reducir su vulnerabilidad ante olas de calor, inundaciones o aumentos en la demanda energética. Desde la perspectiva energética, el pronóstico meteorológico es crucial para integrar fuentes renovables como la energía solar y eólica en los sistemas eléctricos modernos. La generación de energía renovable depende en gran medida de condiciones climáticas, por lo que prever estas variaciones permite una mejor gestión de la oferta y la demanda energética. Según [6], la precisión en el pronóstico del clima mejora la operación de redes inteligentes y reduce los costos de almacenamiento y distribución de energía. En el campo de la salud pública y el cambio climático, los registros meteorológicos históricos son fundamentales para estudiar la relación entre condiciones ambientales y enfermedades [7]. Es por esto que, el análisis y pronóstico del clima permite anticipar y gestionar los efectos del clima en la agricultura, las ciudades, la energía y la salud. El aprovechamiento de estos datos es esencial no solo para la eficiencia operativa, sino también para la construcción de sociedades más resilientes y sostenibles frente al cambio climático global [8]. Finalmente, para este estudio, se analizarán los datos de temperatura media proporcionados por el IDEAM, correspondientes a la estación meteorológica 80222 de la Organización Meteorológica Mundial (WMO), ubicada en el Aeropuerto Internacional El Dorado (SKBO) en Bogotá. Estos datos fueron extraídos mediante la API gratuita de Meteostat en Python. Esta estación representa una fuente confiable y de alta calidad para el monitoreo climático a nivel local, ya que cuenta con registros continuos que permiten complementar el análisis histórico y el modelado climático, proporcionando una perspectiva más precisa del contexto urbano. Referencias [1] Meteostat Project, “Meteostat documentation: Historical weather and climate data.” https://dev.meteostat.net/, 2024. [2] C. Boisvenue and S. W. Running, “Simulated impacts of climate change on forest growth and timber supply in canada,” Climatic Change, vol. 161, pp. 381–395, 2020, doi: 10.1007/s10584-020-02671-1. [3] M. Zampieri, A. Ceglar, F. Dentener, and A. Toreti, “Wheat yield loss attributable to heat waves, drought and water excess at the global, national and subnational scales,” Environmental Research Letters, vol. 16, no. 3, p. 034063, 2021, doi: 10.1088/1748-9326/abd8b2. [4] S. Khaki, L. Wang, and S. V. Archontoulis, “A CNN-RNN framework for crop yield prediction,” Frontiers in Artificial Intelligence, vol. 3, p. 36, 2020, doi: 10.3389/frai.2020.00036. [5] C. Johansson, S. Thorsson, and F. Lindberg, “Urban design and thermal comfort in a changing climate: A case study from sweden,” Urban Climate, vol. 38, p. 100882, 2021, doi: 10.1016/j.uclim.2021.100882. [6] M. Wytock, J. Z. Kolter, and Y. Chen, “Weather-driven predictive modeling for energy systems,” Renewable and Sustainable Energy Reviews, vol. 135, p. 110220, 2021, doi: 10.1016/j.rser.2020.110220. [7] N. Watts et al., “The 2022 report of the lancet countdown on health and climate change: Health at the mercy of fossil fuels,” The Lancet, vol. 400, no. 10363, pp. 1619–1654, 2022, doi: 10.1016/S0140-6736(22)01540-9. [8] IPCC, “Climate change 2021: The physical science basis. Contribution of working group i to the sixth assessment report of the intergovernmental panel on climate change.” Cambridge University Press, 2021. Available: https://www.ipcc.ch/report/ar6/wg1/ "],["medias-móviles-rezagos-y-descomposición-de-la-serie-temporal.html", "Capítulo: 2 Medias Móviles, Rezagos y Descomposición de la Serie Temporal 2.1 Promedios móviles (SMA de 7 y 30 días) 2.2 Rezagos (lags de 1, 7 y 30 días) 2.3 Descomposición STL.", " Capítulo: 2 Medias Móviles, Rezagos y Descomposición de la Serie Temporal Christian Vera, Yuli Deaquiz y Juan Rodríguez 26/04/2025 En primer lugar, se identifica la ventana temporal de las temperaturas registradas por este sensor, la cual comprende datos diarios desde el 1 de enero de 1975 hasta el 31 de marzo de 2025. No obstante, es importante señalar que el conjunto de datos incluye observaciones que se remontan hasta el año 1941, lo que proporciona una perspectiva histórica amplia. Sin embargo, diversos análisis indican que la calidad y confiabilidad de los registros mejora significativamente a partir de 1972, debido a que en los periodos anteriores se observa una alta frecuencia de valores atípicos y anomalías que podrían comprometer la precisión de cualquier análisis basado en dichas observaciones. Por esta razón, los datos previos a 1972 suelen utilizarse con precaución o ser excluidos de los estudios que requieren alta fiabilidad en las series temporales [9]. Teniendo en cuenta lo anterior, se realizaran distintos análisis temporales de la temperatura promedio de la ciudad de Bogotá. Para ello, se aplicarán técnicas de suavizamiento mediante el cálculo de promedios móviles, así como análisis de rezagos y de estacionalidad. Estas aproximaciones permitirán identificar y representar patrones, tendencias y ciclos a lo largo del tiempo. En primer lugar se carga y verifica el tipo de datos del conjunto de datos seleccionado, garantizando que la fecha esté en formato correcto. En el siguiente enlace se puede apreciar el proceso de extracción mediante las API de meteostat y Openmeteo en Python. Notebook de descarga de datos en GitHub Code library(knitr) library(kableExtra) url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) # Mostrar tipo datos datos %&gt;% select(time, tavg) %&gt;% summarise(across(everything(), ~class(.))) %&gt;% pivot_longer(everything(), names_to = &quot;Columna&quot;, values_to = &quot;Tipo de Dato&quot;) %&gt;% kable(format = &quot;html&quot;, align = &quot;c&quot;) %&gt;% kable_styling(full_width = F, position = &quot;center&quot;) Columna Tipo de Dato time Date tavg numeric 2.1 Promedios móviles (SMA de 7 y 30 días) El promedio móvil simple (SMA) es una técnica de suavizamiento que consiste en calcular el promedio de un número fijo de observaciones consecutivas. Sirve para reducir el “ruido” en los datos y destacar patrones como tendencias o ciclos, ayudando en el análisis visual de series de tiempo antes de aplicar modelos más complejos. Se calcularon dos promedios móviles simples (SMA) sobre la variable de temperatura promedio diaria (tavg), utilizando ventanas de 7 y 30 días respectivamente. Para ello, se aplicó la función rollmean, permitiendo un relleno de valores faltantes con NA presente el algunos días de la serie y alineando las medias móviles hacia la derecha. Luego, se construyó un gráfico de líneas que incluye la serie original de temperatura (en gris claro) y las dos curvas suavizadas correspondientes a los promedios móviles (en azul acero para 7 días y rojo oscuro para 30 días). Esta gráfica permite observar la evolución suavizada de la temperatura a lo largo del tiempo, eliminando la variabilidad diaria que puede ocultar patrones generales. El promedio móvil de 7 días capta fluctuaciones semanales, mientras que el de 30 días refleja tendencias de más largo plazo. Al observar esta última, se evidencia una tendencia ascendente en la temperatura promedio, especialmente notable en las últimas décadas. Code library(tidyr) library(dplyr) library(ggplot2) # Cálculo de medias móviles datos_filtrados &lt;- datos_filtrados %&gt;% mutate( sma_7 = rollmean(tavg, k = 7, fill = NA, align = &quot;right&quot;), sma_30 = rollmean(tavg, k = 30, fill = NA, align = &quot;right&quot;)) # gráfica con ggplot grafica &lt;- ggplot(datos_filtrados, aes(x = fecha)) + geom_line(aes(y = tavg, color = &quot;Temperatura Promedio&quot;), size = 0.5) + geom_line(aes(y = sma_7, color = &quot;Media Móvil 7 Días&quot;), size = 0.5) + geom_line(aes(y = sma_30, color = &quot;Media Móvil 30 Días&quot;), size = 0.5) + labs(title = &quot;Temperatura promedio con medias móviles&quot;, x = &quot;Fecha&quot;, y = &quot;Temperatura promedio (°C)&quot;) + scale_color_manual(values = c(&quot;Temperatura Promedio&quot; = &quot;gray70&quot;, &quot;Media Móvil 7 Días&quot; = &quot;steelblue&quot;, &quot;Media Móvil 30 Días&quot; = &quot;darkred&quot;)) + theme_minimal() + theme(legend.title = element_blank(), plot.title = element_text(hjust = 0.5)) print(grafica) 2.2 Rezagos (lags de 1, 7 y 30 días) Un rezago (lag) en series de tiempo consiste en desplazar la serie hacia atrás en el tiempo para observar cómo los valores pasados afectan a los valores presentes o futuros. El análisis de los rezagos permite identificar autocorrelaciones, que son relaciones importantes para modelar y predecir series temporales. Se generaron tres nuevas variables de rezago (lag_1, lag_7 y lag_30), que corresponden a la temperatura promedio registrada hace 1, 7 y 30 días respectivamente. La gráfica ilustra la relación entre la temperatura de un día y la del día anterior. Una correlación positiva sugiere la existencia de dependencia temporal en la serie, es decir, que los valores actuales están influenciados por los valores pasados En este caso se observa una correlación positiva, lo que indica que la temperatura actual tiende a ser más alta cuando la temperatura en el pasado (ya sea hace 1, 7 o 30 días) también fue más alta. Sin embargo, la fuerza de esta correlación disminuye a medida que aumenta el lapso de tiempo, indicando que la temperatura de días más lejanos en el pasado tiene una menor capacidad predictiva sobre la temperatura del presente en comparación con la temperatura de días más recientes. Code library(tidyr) library(dplyr) library(ggplot2) # rezagos datos_filtrados &lt;- datos_filtrados %&gt;% mutate( lag_1 = lag(tavg, 1), lag_7 = lag(tavg, 7), lag_30 = lag(tavg, 30)) datos_filtrados_long &lt;- datos_filtrados %&gt;% gather(key = &quot;lag&quot;, value = &quot;lag_value&quot;, lag_1, lag_7, lag_30) %&gt;% mutate(lag = factor(lag, levels = c(&quot;lag_1&quot;, &quot;lag_7&quot;, &quot;lag_30&quot;))) # Crear la gráfica con ggplot usando facet_wrap grafica &lt;- ggplot(datos_filtrados_long, aes(x = lag_value, y = tavg)) + geom_point(alpha = 0.3, color = &quot;blue&quot;) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, size = 0.5) + # Línea más fina labs(title = &quot;Relación entre temperatura actual y rezago de diferentes días&quot;, x = &quot;Temperatura rezagada&quot;, y = &quot;Temperatura actual&quot;) + facet_wrap(~lag, scales = &quot;free&quot;) + # subgráfica para cada lag theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) # Mostrar la gráfica print(grafica) 2.3 Descomposición STL. La descomposición STL (Seasonal and Trend decomposition using Loess) es una técnica que separa una serie de tiempo en componentes de tendencia, estacionalidad y ruido. Utiliza un enfoque basado en suavizamiento local, que permite capturar patrones no lineales y estacionalidades que pueden cambiar con el tiempo, ofreciendo una interpretación más detallada de la serie. Para analizar la estacionalidad y la tendencia de la serie, se imputaron valores faltantes de la variable tavg mediante interpolación lineal (na.approx). Luego, se transformó la serie en un objeto de tipo ts con frecuencia anual (365 observaciones por año). Se aplicó una descomposición STL (stl) que separa la serie en tendencia, estacionalidad y residuo. La descomposición STL permite visualizar cómo se estructura la variabilidad de la temperatura promedio en sus componentes principales. La tendencia muestra los cambios a largo plazo en la serie, la estacionalidad revela los patrones cíclicos asociados a las distintas épocas del año, y el residuo indica las fluctuaciones irregulares no explicadas. Este análisis es importante para entender los comportamientos recurrentes y para preparar adecuadamente los datos para modelos de pronóstico. En este caso se puede extraer lo siguiente: La tendencia muestra un aumento gradual de la temperatura a lo largo del tiempo, especialmente notable a partir de aproximadamente el año 2000. El componente estacional revela un patrón cíclico que se repite anualmente, lo que sugiere variaciones de temperatura relacionadas con las estaciones del año. El residuo representa las fluctuaciones irregulares que no se explican ni por la tendencia ni por la estacionalidad, indicando la presencia de variabilidad aleatoria o eventos inusuales en los datos de temperatura. Code # Cargar librerías necesarias library(plotly) library(zoo) library(ggplot2) library(lubridate) library(forecast) # Imputamos NA para asegurar continuidad datos_ts &lt;- ts(na.approx(datos_filtrados$tavg, na.rm = FALSE), frequency = 365, start = c(year(min(datos_filtrados$fecha)), yday(min(datos_filtrados$fecha)))) # Descomposición STL descomposicion &lt;- stl(datos_ts, s.window = &quot;periodic&quot;) # Convertir el gráfico ggplot a interactivo con plotly grafico_interactivo &lt;- autoplot(descomposicion) + labs( title = &quot;Descomposición de la serie de temperatura promedio&quot;, x = &quot;Fecha&quot;, y = &quot;Valor&quot; ) + theme_minimal(base_size = 14) + theme( plot.title = element_text(hjust = 0.5, face = &quot;bold&quot;, size = 12, color = &quot;black&quot;), # Cambié el color del título axis.title = element_text(size = 11, color = &quot;black&quot;), # Cambié el color de los títulos de los ejes strip.text = element_text(face = &quot;bold&quot;, size = 11, color = &quot;black&quot;), # Cambié el color del texto de las etiquetas panel.grid.minor = element_blank() ) + # Ajustar el grosor de las líneas y el color de la serie geom_line(size = 0.2, color = &quot;blue&quot;) # Convertir el gráfico ggplot a un gráfico interactivo ggplotly(grafico_interactivo) En conjunto, el uso de estas tres herramientas proporcionan una base para comprender la dinámica de la serie de tiempo. Esta aproximación no solo facilita la detección de ciclos estacionales y tendencias ocultas, sino que también es relevante para diseñar modelos predictivos más robustos. La correcta interpretación de estos componentes permite tomar decisiones mejor informadas en contextos relacionados con el análisis climático o la planificación de recursos Referencias [9] E. Aguilar et al., “Changes in precipitation and temperature extremes in central america and northern south america, 1961–2003,” Journal of Geophysical Research: Atmospheres, vol. 110, no. D23, 2005, doi: https://doi.org/10.1029/2005JD006119. "],["estacionariedad.html", "Capítulo: 3 Estacionariedad 3.1 Preprocesamiento y visualización. 3.2 Diferenciación", " Capítulo: 3 Estacionariedad 3.1 Preprocesamiento y visualización. Christian Vera, Yuli Deaquiz y Juan Rodríguez 04/05/2025 Una serie temporal estacionaria es aquella cuyas propiedades no dependen del momento en que se observa .Por lo tanto, las series temporales con tendencias o con estacionalidad no son estacionarias: la tendencia y la estacionalidad afectarán el valor de la serie temporal en diferentes momentos. Una serie temporal estacionaria no presenta patrones predecibles a largo plazo. Esto implica que si la serie es estacionaria, estaríamos prediciendo que las características estadísticas de nuestra serie de tiempo serán las mismas en el futuro como en el pasado. Para poder comprobar si la serie es estacionaria se puede utilizar algunos métodos estadísticos, entre los más utilizados se encuentran la prueba de Dickey-Fuller Aumentada (ADF) y la prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS). Para nuestro caso usamos las dos pruebas como se muestran a continuación: Code library(knitr) library(kableExtra) library(tidyverse) library(lubridate) library(zoo) library(forecast) url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) datos_filtrados &lt;- datos %&gt;% mutate(fecha = as.Date(time)) %&gt;% arrange(fecha) %&gt;% filter(fecha &gt;= as.Date(&quot;1975-01-01&quot;)) # &#39;tavg&#39; a dos decimales datos_filtrados &lt;- datos_filtrados %&gt;% mutate(tavg = round(tavg, 2)) Prueba de Dickey-Fuller. Code # Prueba de Dickey-Fuller # Ho: La serie no presenta estacionariedad # Ha: La serie presenta estacionariedad ## Prueba de Dickey-Fuller # Ejecutar la prueba Dickey-Fuller library(tseries) library(knitr) library(kableExtra) # Ejecutar la prueba adf_result &lt;- adf.test(datos_filtrados$tavg) # Crear tabla de resultados adf_table &lt;- data.frame( &quot;Test Statistic&quot; = round(adf_result$statistic, 4), &quot;Lag Order&quot; = adf_result$parameter, &quot;p-value&quot; = round(adf_result$p.value, 4), &quot;Alternative&quot; = as.character(adf_result$alternative), check.names = FALSE ) # Mostrar tabla con kableExtra kable(adf_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) Test Statistic Lag Order p-value Alternative Dickey-Fuller -14.5464 26 0.01 stationary Con un p-valor de 0.01, se rechaza la hipótesis nula de no estacionariedad, lo que indica que la serie de la variable temperatura promedio es estacionaria. Esto implica que sus propiedades estadísticas, como la media y la varianza, se mantienen constantes en el tiempo y que la serie no presenta una tendencia sostenida. Prueba KPSS Code # Prueba KPSS # Ho: La serie es estacionaria # Ha: La serie no es estacionaria library(tseries) library(knitr) library(kableExtra) kpss_result &lt;- kpss.test(datos_filtrados$tavg) # Crear tabla de resultados kpss_table &lt;- data.frame( &quot;KPSS Statistic&quot; = round(kpss_result$statistic, 3), &quot;Truncation Lag Parameter&quot; = kpss_result$parameter, &quot;p-value&quot; = round(kpss_result$p.value, 4), check.names = FALSE ) # Mostrar tabla con numeración automática kable(kpss_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot; ) KPSS Statistic Truncation Lag Parameter p-value KPSS Level 34.079 14 0.01 El p-valor es 0.01. Dado que este valor es menor que el nivel de significancia de 0.05, se rechaza la hipótesis nula de estacionariedad. Esto indica que la serie temporal no es estacionaria en nivel, lo cual sugiere que presenta una tendencia sistemática a lo largo del tiempo, como un posible aumento progresivo en la temperatura promedio. Con base en los resultados de las pruebas realizadas, se puede concluir que la serie es estacionaria en diferencias, según el test ADF, pero no lo es en tendencia, según el test KPSS. Por lo tanto, se recomienda llevar a cabo el proceso de diferenciación para lograr la estacionariedad de la serie. 3.2 Diferenciación La diferenciación es una técnica utilizada en el análisis de series temporales para hacer que una serie no estacionaria se vuelva estacionaria. Esto se logra calculando las diferencias entre valores consecutivos de la serie temporal. Así mismo, ayuda a eliminar las tendencias en los datos, haciendo que la serie sea estacionaria. Además, facilita el Modelado ya que al hacer que la serie sea estacionaria, se facilita la aplicación de modelos de series temporales como ARIMA. Para la variable de temperatura promedio se aplicó una diferenciación de primer orden, la cual calcula la diferencia entre cada valor y el anterior en la serie temporal. Posteriormente se realizó nuevamente los test estadísticos de comprobación de la estacionariedad. Dickey-Fuller Test (Diferenciación) Code # Prueba de Dickey-Fuller # Ho: La serie no presenta estacionariedad # Ha: La serie presenta estacionariedad ## Prueba de Dickey-Fuller estacionariedad=diff(datos_filtrados$tavg) #adf.test(estacionariedad) # Ejecutar la prueba Dickey-Fuller library(tseries) library(knitr) library(kableExtra) # Ejecutar la prueba adf_result1 &lt;- adf.test(estacionariedad) # Crear tabla de resultados adf_table &lt;- data.frame( &quot;Test Statistic&quot; = round(adf_result1$statistic, 4), &quot;Lag Order&quot; = adf_result1$parameter, &quot;p-value&quot; = round(adf_result1$p.value, 4), &quot;Alternative&quot; = as.character(adf_result1$alternative), check.names = FALSE ) # Mostrar tabla kable(adf_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) Test Statistic Lag Order p-value Alternative Dickey-Fuller -40.1841 26 0.01 stationary En este caso el valor p de 0.01 indica que se puede rechazar la hipótesis nula de que la serie no es estacionaria, siendo menor al umbral de significancia 0.05. KPSS Test (Diferenciación). Code # Prueba KPSS # Ho: La serie es estacionaria # Ha: La serie no es estacionaria #kpss.test(estacionariedad) library(tseries) library(knitr) library(kableExtra) kpss_result2 &lt;- kpss.test(estacionariedad) # Crear tabla de resultados kpss_table &lt;- data.frame( &quot;KPSS Statistic&quot; = round(kpss_result2$statistic, 3), &quot;Truncation Lag Parameter&quot; = kpss_result2$parameter, &quot;p-value&quot; = round(kpss_result2$p.value, 4), check.names = FALSE) # Mostrar tabla kable(kpss_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) KPSS Statistic Truncation Lag Parameter p-value KPSS Level 0.001 14 0.1 En este caso, el test KPSS aplicado a la serie diferenciada da un valor p de 0.1, lo que sugiere que no hay suficiente evidencia para rechazar la hipótesis nula de estacionariedad en el nivel, indicando que la serie es estacionaria después de la diferenciación. En comparación con el test anterior, donde el valor p era 0.01, que indicaba que la serie no era estacionaria, esta diferencia sugiere que la diferenciación eliminó la tendencia y permitió que la serie se volviera estacionaria. Finalmente, se puede concluir en los dos test estadísticos con un nivel de confianza del 95% que la serie es estacionaria luego de aplicar la diferenciación. Code library(forecast) par(mfrow = c(2, 2), mar = c(5, 5, 3, 1)) # ACF para estacionariedad acf(estacionariedad, lag.max = 34, main = &quot;ACF - Serie diferenciada&quot;) # PACF para estacionariedad pacf(estacionariedad, lag.max = 34, main = &quot;PACF - Serie diferenciada&quot;) # ACF para datos_filtrados$tavg acf(datos_filtrados$tavg, lag.max = 34, main = &quot;ACF - Serie Original&quot;) # PACF para datos_filtrados$tavg pacf(datos_filtrados$tavg, lag.max = 34, main = &quot;PACF - Serie Original&quot;) Figura 3.1 Análisis de Autocorrelación (ACF y PACF) de la serie de temperatura promedio de la ciudad de Bogotá DC. A partir de la Figura 3.1 se puede extraer lo siguiente: ACF - Serie diferenciada: Presenta un pico negativo significativo en el Lag 1, lo que indica una autocorrelación negativa inmediata entre los valores consecutivos después de la diferenciación. Los rezagos posteriores se encuentran dentro de los límites de confianza, lo que sugiere ausencia de autocorrelación significativa en los siguientes periodos, lo cual es un indicativo de una serie estacionaria. PACF - Serie diferenciada: Muestra un pico negativo significativo en el Lag 1, mostrando una fuerte correlación parcial negativa con el primer rezago. Las barras de los rezagos posteriores se mantienen dentro de los límites de confianza, indicando que no hay efectos significativos más allá del primer rezago. Esto sugiere que la serie ha alcanzado estabilidad en sus propiedades estadísticas. ACF - Serie Original: Se observa una reducción lenta de las autocorrelaciones, con barras que permanecen fuera de los límites de confianza en varios rezagos, lo que indica una dependencia temporal y sugiere visualmente que la serie no es estacionaria. Sin embargo, los resultados del test ADF aplicado a la serie original indican que se puede considerar estacionaria desde el punto de vista estadístico PACF - Serie Original: Presenta un pico significativo en el Lag 1 (positivo), lo que indica una fuerte correlación parcial con el primer rezago. Aunque los valores disminuyen rápidamente, algunos rezagos posteriores muestran ligeras significancias, reforzando la idea de no estacionariedad en la serie original y sugiere la necesidad de aplicar una diferenciación para estabilizarla. En resumen, el análisis mostró que la serie de temperatura promedio en Bogotá no es estacionaria al inicio debido a una tendencia, pero al aplicar una diferenciación de primer orden se logra estabilizar. Esto es clave para poder aplicar modelos como ARIMA y hacer predicciones más precisas y confiables. "],["holt-winters..html", "Capítulo: 4 Holt-Winters. 4.1 Ajuste Holt-Winters. 4.2 Pronóstico Holt-Winters (12 meses) 4.3 Métricas de desempeño.", " Capítulo: 4 Holt-Winters. Christian Vera, Yuli Deaquiz y Juan Rodríguez 10/05/2025 El modelo de Holt-Winters, permite analizar series de tiempo univariantes que contienen factores de tendencia y/o estacionalidad, involucrando un enfoque de suavización exponencial con métodos analíticos y patrones aditivos y multiplicativos. Es un método mejorado para calcular pronósticos cuando los datos muestran una tendencia y además estacionalidad, por lo cual se incorporan 3 constantes, que son α y β, según la metodología de Holt el cual tiene encuenta el nivel de los datos y su tendencia, agregando además γ, el cual incluye la estacionalidad, cuyos valores también deben estar entre cero y la unidad. Para este ejercicio se dividio la base de datos en una base de entrenamiento y un test de prueba de la siguiente forma: Base de entrenamiento: del periodo de 1975 a 2021. Base de prueba: periodo de 2022 en adelante. Code # Cargar paquetes necesarios library(tidyverse) library(lubridate) library(forecast) library(kableExtra) # 1. Cargar y preparar los datos url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) datos_filtrados &lt;- datos %&gt;% mutate(fecha = as.Date(time), tavg = round(tavg, 2)) %&gt;% filter(fecha &gt;= as.Date(&quot;1975-01-01&quot;)) %&gt;% arrange(fecha) # 2. Agregar datos por mes (promedio mensual) datos_mensuales &lt;- datos_filtrados %&gt;% mutate(anio_mes = floor_date(fecha, &quot;month&quot;)) %&gt;% group_by(anio_mes) %&gt;% summarise(tavg = mean(tavg, na.rm = TRUE)) %&gt;% ungroup() # 3. Convertir a serie temporal ts_temp &lt;- ts(datos_mensuales$tavg, start = c(year(min(datos_mensuales$anio_mes)), month(min(datos_mensuales$anio_mes))), frequency = 12) # 4. Separar en conjunto de entrenamiento (hasta 2021) y prueba (desde 2022) ts_train &lt;- window(ts_temp, end = c(2021, 12)) ts_test &lt;- window(ts_temp, start = c(2022, 1)) # 5. Ajustar modelo Holt-Winters clásico modelo_hw &lt;- HoltWinters(ts_train) 4.1 Ajuste Holt-Winters. Code # 6. Graficar la serie completa con ajuste # Crear una serie para el ajuste de Holt-Winters ajuste_completo &lt;- ts(fitted(modelo_hw)[,1], start = start(ts_temp), frequency = 12) # Graficar la serie original con el ajuste plot(ts_temp, main = &quot;Serie completa con ajuste Holt-Winters&quot;, col = &quot;blue&quot;, lwd = 2, ylab = &quot;Temperatura&quot;, xlab = &quot;Tiempo&quot;) lines(ajuste_completo, col = &quot;red&quot;, lwd = 1.5) legend(&quot;topright&quot;, legend = c(&quot;Serie completa&quot;, &quot;Ajuste Holt-Winters&quot;), col = c(&quot;blue&quot;, &quot;red&quot;), lwd = 2) Figura 4.1. Serie temporal método Hold-Winters para la temperatura promedio de la ciudad Bogotá DC. Se puede observar en la figura 4.1 que el modelo Hold-Winters muestra un buen ajuste de la variable, ya que la linea roja (modelo de Hold-Winters) es cercana a la serie original (linea azul), sin embargo, no puede captar todas las fluctuaciones menores que puede asociarse a datos atipicos en algunos periodos de tiempo, que pueden estar asociados al fenómeno del niño y la niña. Además, este modelo esta diseñado para capturar patrones de tendencia y regularidad que pueden verse influenciados en este caso por fenomenos climáticos. 4.2 Pronóstico Holt-Winters (12 meses) Code # 7. Pronosticar 36 meses pronostico &lt;- forecast(modelo_hw, h = 12) # 8. Graficar el pronóstico plot(pronostico, main = &quot;Pronóstico Holt-Winters (12 meses)&quot;, xlab = &quot;Tiempo&quot;, ylab = &quot;Temperatura&quot;) Figura 4.2. Pronóstico Holt-Winter para la temperatura promedio de la ciudad de Bogotá DC. En la figura 4.2 se observa con una confiabilidad del 95% representada en las lineas grises, que la temperatura promedio oscilará entre 14 a 15 °C para los siguientes 12 meses entre 2022-1 a 2022-12, sobre los cuales se realizó la evaluación del modelo. 4.3 Métricas de desempeño. Code # 9. Calcular métricas de evaluación sobre el conjunto de prueba metricas &lt;- accuracy(pronostico, ts_test) metricas_df &lt;- as.data.frame(metricas)[2, c(&quot;ME&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;MAPE&quot;)] # Convertir a data frame con nombres descriptivos metricas_df &lt;- data.frame( Métrica = c(&quot;Error Medio (ME)&quot;, &quot;Raíz del Error Cuadrático Medio (RMSE)&quot;, &quot;Error Absoluto Medio (MAE)&quot;, &quot;Error Porcentual Absoluto Medio (MAPE)&quot;), Valor = unlist(metricas_df) ) # 10. Mostrar tabla con el mismo estilo que adf_table kable(metricas_df, align = &quot;c&quot;, row.names = FALSE) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot; ) Métrica Valor Error Medio (ME) -0.7712311 Raíz del Error Cuadrático Medio (RMSE) 0.8424277 Error Absoluto Medio (MAE) 0.7712311 Error Porcentual Absoluto Medio (MAPE) 5.7011795 En relación a la tabla anterior, que reporta las métricas del modelo se puede inferir: Error Medio: con un valor de -0.77 indica que el modelo subestima la temperatura en -0.77°C. Raíz del Cudratíco medio de los errores: con un valor 0.84, esto significa que, en promedio, la desviación de las predicciones del modelo respecto a los valores reales es aproximadamente 0.84 unidades. Un RMSE más bajo indica un mejor ajuste del modelo a los datos, ya que sugiere que los errores de predicción son menores. Error Absoluto Medio: Esto significa que, en promedio, las predicciones del modelo se desvían de los valores reales en aproximadamente 0.77 unidades. A diferencia del RMSE, el MAE no eleva al cuadrado las diferencias, lo que significa que no es tan sensible a los valores atípicos. Error Porcentual Absoluto medio: En terminos relativo las predicciones del modelo estan un 5.7% por encima o por debajo del valor real. Se puede concluir que la predicción a partir del método Holt-Winter tiene un desempeño adecuado para la variable de temperatura promedio, aunque es suceptible de mejoras para reducir el sesgo y minimizar los errores. "],["metodología-box-jenkins.html", "Capítulo: 5 Metodología Box Jenkins 5.1 Cargar y preparar datos 5.2 Visualización inicial de la serie 5.3 Transformación a serie temporal mensual 5.4 Prueba de Estacionariedad (ADF) 5.5 Prueba KPSS 5.6 Diferenciación. 5.7 ACF y PACF 5.8 Ajuste del modelo ARIMA. 5.9 Diagnóstico del modelo 5.10 Pronóstico", " Capítulo: 5 Metodología Box Jenkins Christian Vera, Yuli Deaquiz y Juan Rodríguez 18/05/2025 La metodología Box-Jenkins es una herramienta muy útil cuando queremos entender y predecir el comportamiento de una serie de datos a lo largo del tiempo. Se basa en modelos ARIMA, que permiten analizar si hay patrones repetitivos, tendencias o comportamientos aleatorios en los datos. El proceso consiste en tres pasos,identificar el tipo de modelo que mejor se ajusta, estimar sus parámetros y luego revisar si los errores del modelo (los residuos) no tienen patrones, es decir, que sean impredecibles. En este caso, vamos a aplicar esta metodología a la temperatura promedio mensual de Bogotá desde 1975. Aunque el clima de la ciudad tiende a ser bastante estable por su ubicación y altitud, los datos históricos pueden mostrar cambios sutiles o incluso señales del cambio climático. Con esta técnica, podemos ver cómo ha cambiado la temperatura a lo largo del tiempo y hacer pronósticos que podrían ser útiles para temas como la agricultura, la salud o la planificación urbana. Code # Librerías library(tidyverse) library(forecast) library(tseries) library(knitr) library(kableExtra) library(lubridate) 5.1 Cargar y preparar datos Code # Cargar datos url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) # Filtrar desde 1975 y redondear tavg datos_filtrados &lt;- datos %&gt;% mutate(fecha = as.Date(time), tavg = round(tavg, 2)) %&gt;% filter(fecha &gt;= as.Date(&quot;1975-01-01&quot;)) %&gt;% arrange(fecha) 5.2 Visualización inicial de la serie Code ggplot(datos_filtrados, aes(x = fecha, y = tavg)) + geom_line(color = &quot;#2C3E50&quot;) + labs(title = &quot;Serie de Temperatura Promedio Diaria&quot;, x = &quot;Fecha&quot;, y = &quot;Temperatura (°C)&quot;) + theme_minimal(base_size = 13)+ theme(plot.title = element_text(hjust = 0.5)) Figura 5.1. Serie de temperatura promedio diaria. 5.3 Transformación a serie temporal mensual En primer lugar, se agrupan los datos por mes y se calcula el promedio mensual de temperatura (tavg). Luego, se crea una serie temporal (ts_mensual) con esos valores, indicando que comienza en enero de 1975 y tiene una frecuencia mensual. Code datos_mensual &lt;- datos_filtrados %&gt;% mutate(mes = floor_date(fecha, &quot;month&quot;)) %&gt;% group_by(mes) %&gt;% summarise(tavg = mean(tavg, na.rm = TRUE)) ts_mensual &lt;- ts(datos_mensual$tavg, start = c(1975, 1), frequency = 12) autoplot(ts_mensual, series = &quot;Temperatura&quot;) + ggtitle(&quot;Temperatura Promedio Mensual&quot;) + ylab(&quot;Temperatura (°C)&quot;) + xlab(&quot;Año&quot;) + theme_minimal() + scale_color_manual(values = c(&quot;Temperatura&quot; = &quot;#1F77B4&quot;))+ theme(plot.title = element_text(hjust = 0.5)) Figura 5.2. Temperarura promedio mensual de 1975 a 2020. 5.4 Prueba de Estacionariedad (ADF) La prueba de Dickey-Fuller aumentada (ADF) es una prueba estadística que se utiliza para determinar si una serie temporal es estacionaria, es decir, si sus propiedades estadísticas como la media y la varianza se mantienen constantes en el tiempo. En esta prueba, la hipótesis nula (H₀) establece que la serie no es estacionaria, mientras que la hipótesis alternativa (H₁) afirma que sí lo es. En el resultado obtenido, el valor del estadístico fue -14.5464 y el valor-p fue 0.01, lo que significa que se rechaza la hipótesis nula al nivel de significancia del 5%. Por lo tanto, se concluye que la serie de temperatura promedio (tavg) es estacionaria y puede ser utilizada en modelos que requieren esta condición, como los modelos ARIMA. Code ## Prueba de Dickey-Fuller # Prueba de Dickey-Fuller # Ho: La serie no presenta estacionariedad # Ha: La serie presenta estacionariedad # Ejecutar la prueba Dickey-Fuller library(tseries) library(knitr) library(kableExtra) # Ejecutar la prueba adf_result &lt;- adf.test(datos_filtrados$tavg) # Crear tabla de resultados adf_table &lt;- data.frame( &quot;Test Statistic&quot; = round(adf_result$statistic, 4), &quot;Lag Order&quot; = adf_result$parameter, &quot;p-value&quot; = round(adf_result$p.value, 4), &quot;Alternative&quot; = as.character(adf_result$alternative), check.names = FALSE ) # Mostrar tabla con kableExtra kable(adf_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) Test Statistic Lag Order p-value Alternative Dickey-Fuller -14.5464 26 0.01 stationary 5.5 Prueba KPSS La prueba KPSS es una prueba estadística utilizada para evaluar si una serie temporal es estacionaria en nivel. A diferencia de la prueba ADF, en la KPSS la hipótesis nula (H₀) establece que la serie es estacionaria, mientras que la hipótesis alternativa (H₁) plantea que no es estacionaria. En el resultado mostrado, el estadístico KPSS fue 34.079 con un valor-p de 0.01. Como el valor-p es menor a 0.05, se rechaza la hipótesis nula, lo que indica que la serie de temperatura promedio (tavg) no es estacionaria según esta prueba. Este resultado contradice la prueba ADF, por lo cual es pertinente realizar una diferenciación para confirmar el supuesto de estacionariedad del modelo ARIMA. Code # Prueba KPSS # Ho: La serie es estacionaria # Ha: La serie no es estacionaria library(tseries) library(knitr) library(kableExtra) kpss_result &lt;- kpss.test(datos_filtrados$tavg) # Crear tabla de resultados kpss_table &lt;- data.frame( &quot;KPSS Statistic&quot; = round(kpss_result$statistic, 3), &quot;Truncation Lag Parameter&quot; = kpss_result$parameter, &quot;p-value&quot; = round(kpss_result$p.value, 4), check.names = FALSE ) # Mostrar tabla con numeración automática kable(kpss_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot; ) KPSS Statistic Truncation Lag Parameter p-value KPSS Level 34.079 14 0.01 5.6 Diferenciación. Se aplica una primera diferencia a la serie temporal mensual de temperatura promedio con el objetivo de eliminar tendencias y hacerla estacionaria, es decir, que sus propiedades estadísticas no cambien con el tiempo. Luego, se vuelve a realizar las dos pruebas sobre la serie diferenciada. Los resultados muestran que en la prueba ADF el valor-p es 0.01, lo que lleva a rechazar la hipótesis nula y concluir que la serie diferenciada es estacionaria. Por su parte, en la prueba KPSS el valor-p es 0.1, por lo que no se rechaza la hipótesis nula y se concluye que la serie es estacionaria, lo cual es adecuado para el modelo ARIMA que requiere esta propiedad. Code #Primera diferencia ts_diff1 &lt;- diff(ts_mensual) ### Nuevas pruebas adf_diff &lt;- adf.test(ts_diff1) kpss_diff &lt;- kpss.test(ts_diff1) ### Tabla ADF sobre primera diferencia adf_table &lt;- tibble( Estadístico_ADF = round(adf_diff$statistic, 4), Valor_P = round(adf_diff$p.value, 4), Hipótesis_nula = &quot;La serie NO es estacionaria&quot;, Decisión = ifelse(adf_diff$p.value &lt; 0.05, &quot;Rechazada: la serie ES estacionaria&quot;, &quot;No rechazada: la serie NO es estacionaria&quot;) ) # Mostrar tabla con kableExtra Prueba ADF kable(adf_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) Estadístico_ADF Valor_P Hipótesis_nula Decisión -14.3295 0.01 La serie NO es estacionaria Rechazada: la serie ES estacionaria Code # Tabla KPSS sobre primera diferencia kpss_table &lt;- tibble( Estadístico_KPSS = round(kpss_diff$statistic, 4), Valor_P = kpss_diff$p.value, Hipótesis_nula = &quot;La serie ES estacionaria&quot;, Decisión = ifelse(kpss_diff$p.value &lt; 0.05, &quot;Rechazada: la serie NO es estacionaria&quot;, &quot;No rechazada: la serie ES estacionaria&quot;) ) # Mostrar tabla con kableExtra Prueba KPSS kable(kpss_table, align = &quot;c&quot;) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot;) Estadístico_KPSS Valor_P Hipótesis_nula Decisión 0.0098 0.1 La serie ES estacionaria No rechazada: la serie ES estacionaria 5.7 ACF y PACF Code library(ggplot2) library(forecast) library(patchwork) p1 &lt;- ggAcf(ts_diff1) + theme_minimal() + ggtitle(&quot;ACF de la serie diferenciada&quot;) + theme(plot.title = element_text(hjust = 0.5)) p2 &lt;- ggPacf(ts_diff1) + theme_minimal() + ggtitle(&quot;PACF de la serie diferenciada&quot;) + theme(plot.title = element_text(hjust = 0.5)) p1 + p2 + plot_layout(widths = c(1.5, 1.5)) Figura 5.3. Pruebas ACF y PACF para la serie diferenciada. Los gráficos muestran el análisis de la autocorrelación (ACF) y la autocorrelación parcial (PACF) de la serie temporal después de aplicar la primera diferencia, lo cual ayuda a identificar la estructura de dependencia entre los valores en diferentes rezagos (lags). A continuación se presentan los aspectos mas relevantes de cada uno: ACF:, observamos que la mayoría de los valores caen dentro de las bandas de confianza (líneas azules), lo que indica que no hay una autocorrelación significativa persistente. Esto sugiere que la serie ya no tiene una tendencia clara ni patrones de dependencia fuertes después de ser diferenciada. PACF: se observan algunos picos significativos en los primeros rezagos, pero también la mayoría están dentro de las bandas de confianza. Esto puede indicar que hay ciertas relaciones directas entre la serie actual y algunos rezagos específicos, pero en general, la estructura de dependencia ha disminuido. 5.8 Ajuste del modelo ARIMA. Se utiliza la función auto.arima del paquete forecast para ajustar automáticamente un modelo ARIMA, buscando los valores óptimos de tres parámetros principales: p (el orden de la parte autorregresiva), d (el número de diferencias necesarias para que la serie sea estacionaria) y q (el orden de la media móvil). Además, si la serie temporal presenta estacionalidad, la función también ajusta los parámetros estacionales correspondientes: P, D y Q, que representan patrones repetitivos en intervalos específicos, como meses o trimestres. Code modelo &lt;- auto.arima(ts_mensual, seasonal = TRUE, stepwise = FALSE, approximation = FALSE) summary(modelo) ## Series: ts_mensual ## ARIMA(2,1,1)(2,0,0)[12] ## ## Coefficients: ## ar1 ar2 ma1 sar1 sar2 ## 0.4517 0.2583 -0.9884 0.3165 0.2267 ## s.e. 0.0406 0.0424 0.0059 0.0404 0.0419 ## ## sigma^2 = 0.1513: log likelihood = -285.82 ## AIC=583.65 AICc=583.79 BIC=610.06 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.02932352 0.387005 0.2941109 0.1413283 2.187546 0.6344701 ## ACF1 ## Training set -0.02793378 El modelo ajustado a la serie ts_mensual fue un ARIMA(2,1,1)(2,0,0)[12], lo que significa que se aplicó una diferenciación no estacional de orden 1 (d = 1) para estabilizar la media de la serie, junto con dos términos autorregresivos (p = 2) y uno de media móvil (q = 1). Además, se incluyeron componentes estacionales autorregresivos (P = 2) sin diferenciación estacional (D = 0) ni términos de media móvil estacional (Q = 0), con una periodicidad de 12, lo que indica que se trata de datos mensuales. Los coeficientes estimados para cada parámetro son estadísticamente significativos, como lo sugieren sus errores estándar relativamente bajos. Esto indica que los componentes del modelo capturan adecuadamente la estructura temporal de la serie. En cuanto a la calidad del modelo, la varianza del error fue de 0.1513, lo que indica que los errores de predicción no son muy grandes.Por otro lado, las métricas de error como el RMSE (0.387) y el MAPE (2.19%) muestran que el modelo predice con buena precisión. Finalmente, la autocorrelación del residuo en el primer rezago es muy cercana a cero (-0.028), lo que sugiere que no quedan patrones importantes sin capturar, confirmando que el modelo se ajusta bien a la serie temporal. 5.9 Diagnóstico del modelo 5.9.1 Supuesto de normalidad Code #Ho: los residuales presentan una distribución normal #Ha: los residuales no presentan distribución normal. shapiro.test(resid(modelo)) ## ## Shapiro-Wilk normality test ## ## data: resid(modelo) ## W = 0.98342, p-value = 2.323e-06 De acuerdo al test de shapiro Wilk con un p valor de 2.323e-06 se rechaza la Hiótesis nula lo que indica que los residuales no presentan una distribución normal. Code checkresiduals(modelo) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(2,1,1)(2,0,0)[12] ## Q* = 43.727, df = 19, p-value = 0.00103 ## ## Model df: 5. Total lags used: 24 Figura 5.4 Modelo ARIMA para la temperatura promedio de la ciudad de Bogotá DC. El test de Ljung-Box aplicado a los residuos del modelo ARIMA(2,1,1)(2,0,0)[12] tiene un p-valor de 0.00103, lo cual indica que hay evidencia de autocorrelación en los residuos. En otras palabras, el modelo no logra capturar completamente toda la estructura temporal de la serie, ya que los residuos aún muestran patrones. Adicionalmente, el gráfico muestra los residuos del modelo ARIMA(2,1,1)(2,0,0)[12],permitiendo evaluar si estos se comportan como ruido blanco, es decir, si no presentan patrones visibles. Aunque visualmente los residuos parecen centrarse en torno a cero y distribuidos de forma aproximadamente normal, el gráfico de autocorrelación (ACF) revela que hay varios rezagos que exceden los límites de significancia, lo cual confirma la presencia de autocorrelación presentada en el test Ljung-Box. 5.10 Pronóstico A continuación se presenta el pronóstico con base en el modelo ARIMA(2,1,1)(2,0,0)[12] ajustado a la serie de temperatura mensual. El gráfico muestra la proyección para los próximos 12 meses, incluyendo tanto los valores estimados como los intervalos de confianza que muestran la incentidumbre presentada en cada predicción. Code forecast_temp &lt;- forecast(modelo, h = 12) autoplot(forecast_temp) + labs( title = &quot;Pronóstico de Temperatura para 12 meses&quot;, x = &quot;Año&quot;, y = &quot;Temperatura (°C)&quot; ) + theme_minimal() + theme(plot.title = element_text(hjust = 0.5)) Figura 5.5 Pronóstico de temperatura promedio con el modelo ARIMA. "],["modelo-prophet..html", "Capítulo: 6 Modelo Prophet. 6.1 Cargar los datos. 6.2 Modelo Prophet. 6.3 Predicciones próximos 12 meses. 6.4 Métricas del modelo.", " Capítulo: 6 Modelo Prophet. Christian Vera, Yuli Deaquiz y Juan Rodríguez 23/05/2025 El algoritmo de predicción Prophet se basa en un modelo estadístico aditivo que descompone la serie temporal en tres componentes fundamentales: tendencia, que representa los cambios a largo plazo en el nivel de la serie; estacionalidad, que captura patrones cíclicos o repetitivos a lo largo del tiempo (como variaciones mensuales o anuales); y un componente de eventos especiales o festivos, que permite incorporar el impacto de días atípicos o significativos que pueden afectar la serie temporal [10]. Para la tendencia utiliza una función no lineal que se ajusta a los cambios no periódicos a largo plazo. Para la estacionalidad utiliza un modelo de Fourier para capturar patrones repetitivos. La estacionalidad puede ser modelada como componente aditivo o como componente multiplicativo. 6.1 Cargar los datos. Al igual que en las secciones anteriores se cargan los datos y se calcula la temperatura media mensual para ser usada en una serie de tiempo adecuada para para su análisis y pronóstico mediante el modelo Prophet. Code library(prophet) library(dplyr) library(lubridate) library(ggplot2) library(knitr) library(kableExtra) library(tseries) # Paso 1: Descargar y preparar datos url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) # Paso 2: Filtrar desde 1975 y agrupar por mes datos_mensual &lt;- datos %&gt;% filter(time &gt;= as.Date(&quot;1975-01-01&quot;)) %&gt;% mutate(mes = floor_date(time, &quot;month&quot;), tavg = round(tavg, 2)) %&gt;% group_by(mes) %&gt;% summarise(tavg = mean(tavg, na.rm = TRUE)) %&gt;% ungroup() ts_mensual &lt;- ts(datos_mensual$tavg, start = c(1975, 1), frequency = 12) # Paso 3: Formatear para Prophet (ds = fecha, y = valor) df_prophet &lt;- datos_mensual %&gt;% rename(ds = mes, y = tavg) 6.2 Modelo Prophet. Se genera a partir del algoritmo los parámetros mensuales teniendo en cuenta un modelo aditivo, teniendo presente que la variable de temperatura promedio presenta estacionalidad,en este caso el modelo fue construido con un intervalo de predicción del 95% lo que indica que el valor futuro esta dentro de este rango, con una flexibilidad moderada, lo cual ayudara a identificar cambios grandes y significativos, lo que ayuda a mantener una tendencia estable. Code # Paso 4: Ajustar modelo Prophet con parámetros para series mensuales modelo &lt;- prophet( df_prophet, seasonality.mode = &quot;additive&quot;, yearly.seasonality = TRUE, weekly.seasonality = FALSE, daily.seasonality = FALSE, changepoint.prior.scale = 0.05, interval.width = 0.95 ) 6.3 Predicciones próximos 12 meses. A partir del modelo se realizó la predicción para un periodo de 12 meses desde abril de 2025, donde se estimó con un nivel de confianza del 95% que la temperatura promedio para la ciudad de Bogotá DC en el período 2026-04-01 será de 14.89 °C, con una mínima de 14.02 °C y una máxima 15.75 °C. Además de puede observar una tendencia ascendente en el histórico de la temperatura promedio mensual. Code library(forecast) # Paso 5: Crear horizonte futuro y predecir # Crear horizonte futuro de 12 meses (mensual) futuro &lt;- make_future_dataframe(modelo, periods = 12, freq = &quot;month&quot;) # Realizar la predicción prediccion &lt;- predict(modelo, futuro) prediccion$ds &lt;- as.Date(prediccion$ds) df_prophet$ds &lt;- as.Date(df_prophet$ds) # Paso 6: Graficar resultados # Visualización base con intervalos de confianza) forecast=predict(modelo,futuro) dyplot.prophet(modelo, forecast) Code # Componentes del modelo (tendencia y estacionalidad) prophet_plot_components(modelo,forecast) Code tail(forecast[c(&#39;ds&#39;, &#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) ## ds yhat yhat_lower yhat_upper ## 611 2025-11-01 14.32865 13.48286 15.14963 ## 612 2025-12-01 14.07406 13.25651 14.82452 ## 613 2026-01-01 13.89356 13.06385 14.69248 ## 614 2026-02-01 14.41209 13.59986 15.17168 ## 615 2026-03-01 14.62050 13.78086 15.40624 ## 616 2026-04-01 14.89764 14.02295 15.71549 6.4 Métricas del modelo. Code # Paso 7: Calcular métricas sobre datos históricos pred_train &lt;- prediccion %&gt;% filter(ds &lt;= max(df_prophet$ds)) %&gt;% select(ds, yhat) # Comparar con datos reales evaluacion_completa &lt;- df_prophet %&gt;% left_join(pred_train, by = &quot;ds&quot;) %&gt;% mutate( error = y - yhat, abs_error = abs(error), sq_error = error^2, pe = error / y, ape = abs(error / y) ) # Calcular métricas me_total &lt;- mean(evaluacion_completa$error, na.rm = TRUE) rmse_total &lt;- sqrt(mean(evaluacion_completa$sq_error, na.rm = TRUE)) mae_total &lt;- mean(evaluacion_completa$abs_error, na.rm = TRUE) mpe_total &lt;- mean(evaluacion_completa$pe, na.rm = TRUE) * 100 mape_total &lt;- mean(evaluacion_completa$ape, na.rm = TRUE) * 100 # MASE mae_naive_total &lt;- mean(abs(diff(df_prophet$y)), na.rm = TRUE) mase_total &lt;- mae_total / mae_naive_total ##------------------------------------- ##Tabla en Kable Extra con los resultados ##------------------------------------- tabla_metricas &lt;- data.frame( Métrica = c(&quot;ME&quot;, &quot;RMSE&quot;, &quot;MAE&quot;, &quot;MPE (%)&quot;, &quot;MAPE (%)&quot;, &quot;MASE&quot;), Valor = round(c(me_total, rmse_total, mae_total, mpe_total, mape_total, mase_total), 3) ) kable(tabla_metricas) %&gt;% kable_styling( bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE, position = &quot;center&quot; ) Métrica Valor ME 0.000 RMSE 0.422 MAE 0.323 MPE (%) -0.101 MAPE (%) 2.404 MASE 0.913 A continuación se resaltan los aspectos mas relevantes de las métricas obtenidas. ME (Error Medio): El valor de ME es 0.000, lo que indica que, en promedio, el modelo no tiene sesgo y las predicciones son bastante centradas alrededor de los valores reales. Esto sugiere que el modelo no tiende a sobrestimar ni subestimar sistemáticamente. RMSE (Raíz del Error Cuadrático Medio): Con un valor de 0.422, el RMSE proporciona una medida de la magnitud promedio de los errores de predicción, este valor indica un buen ajuste del modelo. MAE (Error Absoluto Medio): El MAE de 0.323 indica el promedio de los errores absolutos entre las predicciones y los valores reales, siendo un valor bajo que lo podemos asociar a un buen ajuste de la variable temperatura a este modelo de predicción. MPE (Error Porcentual Medio): Con un valor de -0.101%, el MPE indica que, en promedio, las predicciones son ligeramente menores que los valores reales, pero el porcentaje es muy pequeño, lo que sugiere que el modelo es bastante preciso en términos porcentuales. MAPE (Error Porcentual Absoluto Medio): El MAPE de 2.404% indica que, en promedio, las predicciones están dentro de un 2.404% de los valores reales. lo cual lo podemos asociar a un un buen nivel de precisión, teniendo en cuenta que el nivel de confianza usado es del 95%. Finalmente, este modelo es aplicable a la variable en estudio “Temperatura promedio de la ciudad de Bogotá”, teniendo presente la tendencia y estacionalidad presente en este conjunto de datos. Referencias [10] S. J. Taylor and B. L. and, “Forecasting at scale,” The American Statistician, vol. 72, no. 1, pp. 37–45, 2018, doi: 10.1080/00031305.2017.1380080. "],["redes-de-elman-y-jordan..html", "Capítulo: 7 Redes de ELMAN y Jordan. 7.1 Carga de datos. 7.2 Preparación de datos para RSNNS. 7.3 Optimización de hiperparámetros. 7.4 Tabla de mejores parámetros 7.5 Visualización con Plotly 7.6 Métricas de Desempeño. 7.7 Predicciones de Temperatura (°C) - Próximos 12 Meses.", " Capítulo: 7 Redes de ELMAN y Jordan. Christian Vera, Yuli Deaquiz y Juan Rodríguez 06/06/2025 Las redes neuronales de Elman y Jordan son dos tipos de redes neuronales recurrentes (RNN), las cuales tienen como característica principal que incorporan conexiones de retroalimentación para el procesamiento de secuencias de datos, como por ejemplo series de tiempo, texto o señales. Ambos modelos extienden la arquitectura de las redes neuronales tradicionales añadiendo una memoria temporal que les permite recordar información de pasos anteriores, lo cual es esencial para detectar patrones temporales o secuenciales. Red neuronal de Elman: es un tipo de red neuronal recurrente que incorpora una capa de contexto donde se almacenan los valores anteriores de la capa oculta. Esta estructura le permite mantener una forma de memoria temporal, la cual es de utilidad para procesar datos secuenciales como series de tiempo. Al usar tanto la entrada actual como el estado oculto previo, la red puede aprender patrones dinámicos en los datos, lo que la hace ideal para tareas donde el pasado influye directamente en el futuro. Red neuronal de Jordan: es una red recurrente, pero en lugar de retroalimentar la capa oculta, retroalimenta la salida del modelo hacia una capa de contexto. Esta capa actúa como memoria de las predicciones anteriores, que se combinan con la entrada actual para generar la próxima salida. De esta forma, el modelo tiene en cuenta sus propias decisiones pasadas al hacer nuevas predicciones, lo que es útil en sistemas donde el comportamiento anterior del modelo afecta el futuro, como en control de procesos o generación de secuencias. A continuación se realiza el pronóstico de la serie temporal de la temperatura en la ciudad de Bogotá utilizando redes neuronales recurrentes de tipo Elman y Jordan. Para ello, se emplean los datos mensuales desde 1975, los cuales son normalizados y estructurados con rezagos para capturar la estacionalidad anual. Ambos modelos son entrenados sobre esta serie y posteriormente se realiza una proyección a 12 meses hacia el futuro de manera autoregresiva, es decir, utilizando las propias predicciones del modelo como insumo para los siguientes pasos. Finalmente, se visualizan tanto los ajustes sobre los datos históricos como las proyecciones futuras, y se evalúa el desempeño de cada red mediante métricas de error como ME, MAE, MPE y MAPE, con el objetivo de comparar su capacidad predictiva. 7.1 Carga de datos. En primer lugar se filtran los datos a partir de 1975 y a igual que en los casos anteriores se calcula la temperatura promedio mensual. Code # Cargar librerías necesarias suppressPackageStartupMessages({ library(tidyverse) library(kableExtra) library(plotly) }) library(lubridate) library(RSNNS) library(Metrics) # Descargar y preparar datos url &lt;- &quot;https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv&quot; datos &lt;- read.csv(url) datos$time &lt;- as.Date(datos$time) # Datos mensuales datos_mensual &lt;- datos %&gt;% filter(time &gt;= as.Date(&quot;1975-01-01&quot;)) %&gt;% mutate(mes = floor_date(time, &quot;month&quot;), tavg = round(tavg, 2)) %&gt;% group_by(mes) %&gt;% summarise(tavg = mean(tavg, na.rm = TRUE)) %&gt;% ungroup() ts_mensual_original &lt;- ts(datos_mensual$tavg, start = c(1975, 1), frequency = 12) 7.2 Preparación de datos para RSNNS. Posteriormente se normaliza la serie temporal de temperaturas para obtener valores entre 0 y 1. Seguidamente se crea una matriz con 12 rezagos, que usa los valores de los 12 meses anteriores para predecir el siguiente mes y de esta manera capturar la estacionalidad anual de la serie de tiempo. Code # 1. Preparación de datos para RSNNS # Normalización de la serie min_val &lt;- min(ts_mensual_original) max_val &lt;- max(ts_mensual_original) ts_mensual_norm &lt;- (ts_mensual_original - min_val) / (max_val - min_val) # Función para crear matriz de lags create_lagged_matrix &lt;- function(data, lags = 12) { n &lt;- length(data) input_matrix &lt;- matrix(nrow = n - lags, ncol = lags) output_vector &lt;- numeric(n - lags) for (i in 1:(n - lags)) { input_matrix[i, ] &lt;- data[i:(i + lags - 1)] output_vector[i] &lt;- data[i + lags] } list(inputs = input_matrix, targets = output_vector) } # Usaremos 12 lags para capturar la estacionalidad anual num_lags &lt;- 12 lagged_data &lt;- create_lagged_matrix(ts_mensual_norm, lags = num_lags) inputs &lt;- lagged_data$inputs targets &lt;- lagged_data$targets # Función de denormalización denormalize &lt;- function(x_norm, min_val, max_val) { x_norm * (max_val - min_val) + min_val } 7.3 Optimización de hiperparámetros. Para obtener mejores resultados es pertinente evaluar la mejor combinación de parámetros que garantice un equilibrio óptimo entre capacidad de aprendizaje, velocidad de convergencia y tiempo de entrenamiento, evitando tanto el subajuste (modelo demasiado simple) como el sobreajuste (modelo que se ajusta demasiado a los datos de entrenamiento. Para esto se evaluan las distintas combinaciones de los parametrosde número de neuronas ocultas (hidden_units), tasas de aprendizaje (learning_rate) y número máximo de iteraciones (max_iter). El parámetro hidden_units define cuántas neuronas hay en la capa oculta de la red, afectando la capacidad del modelo para aprender patrones complejos. learning_rate controla qué tan rápido se ajustan los pesos durante el entrenamiento, influyendo directamente en la calidad del aprendizaje y max_iter determina el máximo número de ciclos de entrenamiento, limitando el tiempo de entrenamiento y evitando sobre ajuste. Para llevar a cabo la evaluación de estas combinaciones se utiliza validación cruzada temporal en 5 pliegues y se seleccionan los mejores parámetros basados en el menor MSE promedio para entrenar los modelos finales. Code ## 2. OPTIMIZACIÓN DE HIPERPARÁMETROS # Definir grilla de parámetros a probar param_grid &lt;- expand.grid( hidden_units = c(5, 8, 10, 15, 20), learning_rate = c(0.001, 0.01, 0.05, 0.1), max_iter = c(50, 100, 150, 200) ) # Función para validación cruzada con series temporales time_series_cv &lt;- function(inputs, targets, param_grid, k_folds = 5) { n &lt;- nrow(inputs) fold_size &lt;- floor(n / k_folds) results_elman &lt;- data.frame() results_jordan &lt;- data.frame() cat(&quot;Iniciando optimización de hiperparámetros...\\n&quot;) cat(&quot;Total de combinaciones a probar:&quot;, nrow(param_grid), &quot;\\n&quot;) for (i in 1:nrow(param_grid)) { hidden_units &lt;- param_grid$hidden_units[i] learning_rate &lt;- param_grid$learning_rate[i] max_iter &lt;- param_grid$max_iter[i] if (i %% 10 == 0) { cat(&quot;Progreso:&quot;, i, &quot;/&quot;, nrow(param_grid), &quot;\\n&quot;) } cv_errors_elman &lt;- numeric(k_folds) cv_errors_jordan &lt;- numeric(k_folds) for (fold in 1:k_folds) { # División temporal de los datos test_start &lt;- (fold - 1) * fold_size + 1 test_end &lt;- min(fold * fold_size, n) if (test_start &gt; 1) { train_inputs &lt;- inputs[1:(test_start-1), , drop = FALSE] train_targets &lt;- targets[1:(test_start-1)] test_inputs &lt;- inputs[test_start:test_end, , drop = FALSE] test_targets &lt;- targets[test_start:test_end] # Entrenar modelos solo si hay suficientes datos de entrenamiento if (nrow(train_inputs) &gt; hidden_units) { tryCatch({ # Modelo Elman set.seed(123) model_elman &lt;- elman(train_inputs, train_targets, size = c(hidden_units), learnFuncParams = c(learning_rate), maxit = max_iter, linOut = TRUE) pred_elman &lt;- predict(model_elman, test_inputs) cv_errors_elman[fold] &lt;- mean((test_targets - pred_elman)^2) # Modelo Jordan set.seed(123) model_jordan &lt;- jordan(train_inputs, train_targets, size = c(hidden_units), learnFuncParams = c(learning_rate), maxit = max_iter, linOut = TRUE) pred_jordan &lt;- predict(model_jordan, test_inputs) cv_errors_jordan[fold] &lt;- mean((test_targets - pred_jordan)^2) }, error = function(e) { cv_errors_elman[fold] &lt;- Inf cv_errors_jordan[fold] &lt;- Inf }) } else { cv_errors_elman[fold] &lt;- Inf cv_errors_jordan[fold] &lt;- Inf } } else { cv_errors_elman[fold] &lt;- Inf cv_errors_jordan[fold] &lt;- Inf } } # Guardar resultados results_elman &lt;- rbind(results_elman, data.frame( hidden_units = hidden_units, learning_rate = learning_rate, max_iter = max_iter, cv_mse = mean(cv_errors_elman[is.finite(cv_errors_elman)]) )) results_jordan &lt;- rbind(results_jordan, data.frame( hidden_units = hidden_units, learning_rate = learning_rate, max_iter = max_iter, cv_mse = mean(cv_errors_jordan[is.finite(cv_errors_jordan)]) )) } return(list(elman = results_elman, jordan = results_jordan)) } # Ejecutar optimización cat(&quot;Ejecutando validación cruzada...\\n&quot;) cv_results &lt;- time_series_cv(inputs, targets, param_grid, k_folds = 5) # Encontrar mejores parámetros best_params_elman &lt;- cv_results$elman[which.min(cv_results$elman$cv_mse), ] best_params_jordan &lt;- cv_results$jordan[which.min(cv_results$jordan$cv_mse), ] cat(&quot;Optimización completada!\\n\\n&quot;) # Mostrar mejores parámetros de forma limpia cat(&quot;=== MEJORES PARÁMETROS ENCONTRADOS ===\\n&quot;) cat(&quot;Mejores parámetros Elman:\\n&quot;) cat(&quot; Neuronas ocultas:&quot;, best_params_elman$hidden_units, &quot;\\n&quot;) cat(&quot; Tasa de aprendizaje:&quot;, best_params_elman$learning_rate, &quot;\\n&quot;) cat(&quot; Máx. iteraciones:&quot;, best_params_elman$max_iter, &quot;\\n&quot;) cat(&quot; MSE validación:&quot;, round(best_params_elman$cv_mse, 6), &quot;\\n\\n&quot;) cat(&quot;Mejores parámetros Jordan:\\n&quot;) cat(&quot; Neuronas ocultas:&quot;, best_params_jordan$hidden_units, &quot;\\n&quot;) cat(&quot; Tasa de aprendizaje:&quot;, best_params_jordan$learning_rate, &quot;\\n&quot;) cat(&quot; Máx. iteraciones:&quot;, best_params_jordan$max_iter, &quot;\\n&quot;) cat(&quot; MSE validación:&quot;, round(best_params_jordan$cv_mse, 6), &quot;\\n\\n&quot;) Code # 3. Entrenar modelos finales con mejores parámetros cat(&quot;Entrenando modelos finales con mejores parámetros...\\n&quot;) # --- Red Elman con mejores parámetros --- set.seed(123) elman_model_optimized &lt;- elman(inputs, targets, size = c(best_params_elman$hidden_units), learnFuncParams = c(best_params_elman$learning_rate), maxit = best_params_elman$max_iter, linOut = TRUE) fitted_elman_norm &lt;- predict(elman_model_optimized, inputs) # --- Red Jordan con mejores parámetros --- set.seed(123) jordan_model_optimized &lt;- jordan(inputs, targets, size = c(best_params_jordan$hidden_units), learnFuncParams = c(best_params_jordan$learning_rate), maxit = best_params_jordan$max_iter, linOut = TRUE) fitted_jordan_norm &lt;- predict(jordan_model_optimized, inputs) # 4. Denormalización de resultados fitted_elman &lt;- denormalize(fitted_elman_norm, min_val, max_val) fitted_jordan &lt;- denormalize(fitted_jordan_norm, min_val, max_val) # Los valores ajustados no cubren los primeros num_lags puntos originales full_fitted_elman &lt;- c(rep(NA, num_lags), fitted_elman) full_fitted_jordan &lt;- c(rep(NA, num_lags), fitted_jordan) # 5. Proyección a 12 meses con modelos optimizados n_forecast &lt;- 12 forecast_elman_norm &lt;- numeric(n_forecast) forecast_jordan_norm &lt;- numeric(n_forecast) # Últimos num_lags valores normalizados de la serie original para iniciar la predicción current_input_elman &lt;- tail(ts_mensual_norm, num_lags) current_input_jordan &lt;- tail(ts_mensual_norm, num_lags) for (i in 1:n_forecast) { # Predicción Elman pred_elman_norm &lt;- predict(elman_model_optimized, matrix(current_input_elman, nrow = 1)) forecast_elman_norm[i] &lt;- pred_elman_norm[1,1] current_input_elman &lt;- c(current_input_elman[-1], pred_elman_norm[1,1]) # Predicción Jordan pred_jordan_norm &lt;- predict(jordan_model_optimized, matrix(current_input_jordan, nrow = 1)) forecast_jordan_norm[i] &lt;- pred_jordan_norm[1,1] current_input_jordan &lt;- c(current_input_jordan[-1], pred_jordan_norm[1,1]) } # Denormalizar proyecciones forecast_elman &lt;- denormalize(forecast_elman_norm, min_val, max_val) forecast_jordan &lt;- denormalize(forecast_jordan_norm, min_val, max_val) 7.4 Tabla de mejores parámetros Code # 6. Tabla de mejores parámetros tabla_mejores_parametros &lt;- data.frame( Modelo = c(&quot;Elman&quot;, &quot;Jordan&quot;), Neuronas_Ocultas = c(best_params_elman$hidden_units, best_params_jordan$hidden_units), Tasa_Aprendizaje = c(best_params_elman$learning_rate, best_params_jordan$learning_rate), Max_Iteraciones = c(best_params_elman$max_iter, best_params_jordan$max_iter), MSE_Validacion = round(c(best_params_elman$cv_mse, best_params_jordan$cv_mse), 6) ) # TABLA DE MEJORES PARÁMETROS kable(tabla_mejores_parametros, col.names = c(&quot;Modelo&quot;, &quot;Neuronas Ocultas&quot;, &quot;Tasa de Aprendizaje&quot;, &quot;Máx. Iteraciones&quot;, &quot;MSE Validación&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE) %&gt;% column_spec(1, bold = TRUE) Modelo Neuronas Ocultas Tasa de Aprendizaje Máx. Iteraciones MSE Validación Elman 8 0.01 200 0.010711 Jordan 5 0.01 200 0.012951 7.5 Visualización con Plotly A continuación se presenta la visualización de las predicciones realizadas de los dos modelos, junto con su ajuste y los valores reales de la serie. 7.6 Métricas de Desempeño. Code # 8. Tabla de Métricas de Desempeño (sobre el conjunto de entrenamiento) library(Metrics) # Asegúrate de tener esta librería cargada n_entrenamiento &lt;- length(targets) original_for_metrics &lt;- tail(ts_mensual_original, n_entrenamiento) fitted_elman_for_metrics &lt;- head(fitted_elman, n_entrenamiento) fitted_jordan_for_metrics &lt;- head(fitted_jordan, n_entrenamiento) # Calcular métricas para Elman metrics_elman &lt;- data.frame( Metrica = c(&quot;ME (Error Medio)&quot;, &quot;RMSE (Raíz del Error Cuadrático Medio)&quot;, &quot;MAE (Error Absoluto Medio)&quot;, &quot;MPE (Error Porcentual Medio)&quot;, &quot;MAPE (Error Porcentual Absoluto Medio)&quot;), Valor = c( mean(original_for_metrics - fitted_elman_for_metrics), rmse(original_for_metrics, fitted_elman_for_metrics), mae(original_for_metrics, fitted_elman_for_metrics), mean((original_for_metrics - fitted_elman_for_metrics) / original_for_metrics) * 100, mape(original_for_metrics, fitted_elman_for_metrics) * 100 ) ) # Calcular métricas para Jordan metrics_jordan &lt;- data.frame( Metrica = c(&quot;ME (Error Medio)&quot;, &quot;RMSE (Raíz del Error Cuadrático Medio)&quot;, &quot;MAE (Error Absoluto Medio)&quot;, &quot;MPE (Error Porcentual Medio)&quot;, &quot;MAPE (Error Porcentual Absoluto Medio)&quot;), Valor = c( mean(original_for_metrics - fitted_jordan_for_metrics), rmse(original_for_metrics, fitted_jordan_for_metrics), mae(original_for_metrics, fitted_jordan_for_metrics), mean((original_for_metrics - fitted_jordan_for_metrics) / original_for_metrics) * 100, mape(original_for_metrics, fitted_jordan_for_metrics) * 100 ) ) # Combinar métricas en una tabla tabla_metricas &lt;- rbind( cbind(Modelo = &quot;Elman&quot;, metrics_elman), cbind(Modelo = &quot;Jordan&quot;, metrics_jordan) ) tabla_metricas$Valor &lt;- round(tabla_metricas$Valor, 4) # Mostrar tabla de métricas kable(tabla_metricas) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE) %&gt;% column_spec(1, bold = TRUE) %&gt;% collapse_rows(columns = 1, valign = &quot;top&quot;) Modelo Metrica Valor Elman ME (Error Medio) -0.2647 RMSE (Raíz del Error Cuadrático Medio) 0.4850 MAE (Error Absoluto Medio) 0.3923 MPE (Error Porcentual Medio) -2.0745 MAPE (Error Porcentual Absoluto Medio) 2.9663 Jordan ME (Error Medio) -0.2219 RMSE (Raíz del Error Cuadrático Medio) 0.4933 MAE (Error Absoluto Medio) 0.3904 MPE (Error Porcentual Medio) -1.7719 MAPE (Error Porcentual Absoluto Medio) 2.9479 A continuación se resaltan los aspectos mas relevantes de las métricas obtenidas: 7.6.1 Modelo ELMAN: ME (Error Medio): El valor de ME es -0.2647, lo que indica que, en promedio, el modelo tiende a subestimar levemente las temperaturas reales. Aunque el sesgo es negativo, su magnitud es moderada, por lo que no representa un desajuste grave. RMSE (Raíz del Error Cuadrático Medio): El RMSE es 0.4850, lo cual representa el error promedio en términos de desviación cuadrática. Aunque mayor que el MAE, este valor sigue siendo razonablemente bajo, lo que sugiere un ajuste aceptable. MAE (Error Absoluto Medio): El valor de 0.3923 representa el promedio de los errores absolutos, indicando que las predicciones se desvían en promedio unos 0.39 grados de los valores reales. Es un valor moderadamente bajo, compatible con un desempeño sólido del modelo. MPE (Error Porcentual Medio): Con un MPE de -2.0745%, el modelo tiende a subestimar en promedio las temperaturas en un 2.07%. Aunque hay un sesgo, este es moderado, lo cual puede ser aceptable en el contexto climático. MAPE (Error Porcentual Absoluto Medio): El MAPE de 2.9663% indica que, en promedio, las predicciones del modelo Elman están dentro de un 3% de los valores reales. Esto sugiere un nivel de precisión bastante bueno, especialmente en series temporales de temperatura. 7.6.2 Modelo Jordan: ME (Error Medio): El valor de -0.2219 muestra que el modelo Jordan también subestima ligeramente los valores reales, aunque en menor medida en comparación que Elman RMSE (Raíz del Error Cuadrático Medio): El RMSE es 0.4933, ligeramente superior al de Elman, lo que indica que los errores más grandes tienen un efecto levemente mayor en este modelo. Aun así, el valor es bajo y representa un buen ajuste global. MAE (Error Absoluto Medio): El valor de 0.3904 es similar al de Elman, lo que indica una precisión similar en términos de error absoluto promedio. MPE (Error Porcentual Medio): Con -1.7719%, el modelo Jordan tiene un sesgo porcentual menor que Elman, lo cual sugiere una menor tendencia a subestimar las temperaturas. MAPE (Error Porcentual Absoluto Medio): El valor de 2.9479% indica que, en promedio, las predicciones están dentro de un 2.95% de los valores reales, reflejando una muy buena capacidad predictiva del modelo Jordan, ligeramente mejor que Elman en este aspecto. 7.7 Predicciones de Temperatura (°C) - Próximos 12 Meses. Code # 9. Resumen de predicciones # PREDICCIONES PARA LOS PRÓXIMOS 12 MESES df_predicciones &lt;- data.frame( Mes = format(fechas_proyeccion, &quot;%Y-%m&quot;), Elman_Optimizado = round(forecast_elman, 2), Jordan_Optimizado = round(forecast_jordan, 2) ) kable(df_predicciones, col.names = c(&quot;Mes&quot;, &quot;Elman Optimizado&quot;, &quot;Jordan Optimizado&quot;)) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;), full_width = FALSE) Mes Elman Optimizado Jordan Optimizado 2025-05 14.64 14.61 2025-06 14.47 14.45 2025-07 14.49 14.45 2025-08 14.43 14.48 2025-09 14.54 14.47 2025-10 14.37 14.52 2025-11 14.38 14.35 2025-12 14.25 14.32 2026-01 14.22 14.20 2026-02 14.29 14.28 2026-03 14.33 14.28 2026-04 14.43 14.35 "],["referencias.html", "Referencias", " Referencias [1] Meteostat Project, “Meteostat documentation: Historical weather and climate data.” https://dev.meteostat.net/, 2024. [2] C. Boisvenue and S. W. Running, “Simulated impacts of climate change on forest growth and timber supply in canada,” Climatic Change, vol. 161, pp. 381–395, 2020, doi: 10.1007/s10584-020-02671-1. [3] M. Zampieri, A. Ceglar, F. Dentener, and A. Toreti, “Wheat yield loss attributable to heat waves, drought and water excess at the global, national and subnational scales,” Environmental Research Letters, vol. 16, no. 3, p. 034063, 2021, doi: 10.1088/1748-9326/abd8b2. [4] S. Khaki, L. Wang, and S. V. Archontoulis, “A CNN-RNN framework for crop yield prediction,” Frontiers in Artificial Intelligence, vol. 3, p. 36, 2020, doi: 10.3389/frai.2020.00036. [5] C. Johansson, S. Thorsson, and F. Lindberg, “Urban design and thermal comfort in a changing climate: A case study from sweden,” Urban Climate, vol. 38, p. 100882, 2021, doi: 10.1016/j.uclim.2021.100882. [6] M. Wytock, J. Z. Kolter, and Y. Chen, “Weather-driven predictive modeling for energy systems,” Renewable and Sustainable Energy Reviews, vol. 135, p. 110220, 2021, doi: 10.1016/j.rser.2020.110220. [7] N. Watts et al., “The 2022 report of the lancet countdown on health and climate change: Health at the mercy of fossil fuels,” The Lancet, vol. 400, no. 10363, pp. 1619–1654, 2022, doi: 10.1016/S0140-6736(22)01540-9. [8] IPCC, “Climate change 2021: The physical science basis. Contribution of working group i to the sixth assessment report of the intergovernmental panel on climate change.” Cambridge University Press, 2021. Available: https://www.ipcc.ch/report/ar6/wg1/ [9] E. Aguilar et al., “Changes in precipitation and temperature extremes in central america and northern south america, 1961–2003,” Journal of Geophysical Research: Atmospheres, vol. 110, no. D23, 2005, doi: https://doi.org/10.1029/2005JD006119. [10] S. J. Taylor and B. L. and, “Forecasting at scale,” The American Statistician, vol. 72, no. 1, pp. 37–45, 2018, doi: 10.1080/00031305.2017.1380080. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
