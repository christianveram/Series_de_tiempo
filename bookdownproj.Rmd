---
title: " Temperatura histórica en la ciudad de Bogotá."
author: "**Christian Vera, Yuli Deaquiz y Juan Rodríguez** "
date: "12/04/2025"
bibliography: referencias.bib
link-citations: true
csl: ieee.csl
site: bookdown::bookdown_site
---


# Introducción

La base de datos de **Meteostat** es una fuente robusta y accesible de información meteorológica histórica, que abarca variables como temperatura, precipitación, humedad, presión atmosférica y velocidad del viento, recopiladas desde estaciones meteorológicas distribuidas a nivel global. Esta plataforma es una herramienta importante para la investigación climática y ambiental, tiene cobertura temporal desde inicios del siglo XX y tiene actualización continua con datos diarios y horarios. Además, esta base de datos integra fuentes oficiales como servicios meteorológicos nacionales, redes de observación internacionales y datos satelitales, lo cual garantiza un alto nivel de confiabilidad y precisión en la generación de modelos predictivos y generación de escenarios de cambio climático[@meteostat2024].

Por lo que, el análisis y pronóstico de datos meteorológicos es una herramienta clave para diversos sectores productivos y sociales, al permitir anticipar condiciones ambientales que impactan directamente en la operación, sostenibilidad y toma de decisiones[@boisvenue2020simulated]. Un ejemplo de ello se da en el sector agrícola, donde el uso de datos meteorológicos permite optimizar épocas de siembra, uso adecuado del agua y zonas aptas para el establecimiento de cultivos. De acuerdo con [@zampieri2021wheat], el cambio climático afecta el rendimiento agrícola, por lo que integrar esta información a los sistemas de decisión puede mejorar la producción. Asimismo, [@khaki2020cnn] muestran cómo los modelos de predicción basados en datos meteorológicos mejoran la precisión del pronóstico de rendimiento de cultivos, permitiendo una planificación más eficiente.

En el ámbito urbano, el análisis climático apoya la planificación de infraestructuras y ciudades más adaptadas al calentamiento global. Estudios han demostrado que las proyecciones meteorológicas, combinadas con datos históricos, permiten modelar el impacto y mejorar el diseño urbano para enfrentar eventos extremos [@johansson2021urban]. Ciudades que integran esta información pueden reducir su vulnerabilidad ante olas de calor, inundaciones o aumentos en la demanda energética. Desde la perspectiva energética, el pronóstico meteorológico es crucial para integrar fuentes renovables como la energía solar y eólica en los sistemas eléctricos modernos.

La generación de energía renovable depende en gran medida de condiciones climáticas, por lo que prever estas variaciones permite una mejor gestión de la oferta y la demanda energética. Según [@wytock2021weather], la precisión en el pronóstico del clima mejora la operación de redes inteligentes y reduce los costos de almacenamiento y distribución de energía. En el campo de la salud pública y el cambio climático, los registros meteorológicos históricos son fundamentales para estudiar la relación entre condiciones ambientales y enfermedades [@watts2022lancet].

Es por esto que, el análisis y pronóstico del clima permite anticipar y gestionar los efectos del clima en la agricultura, las ciudades, la energía y la salud. El aprovechamiento de estos datos es esencial no solo para la eficiencia operativa, sino también para la construcción de sociedades más resilientes y sostenibles frente al cambio climático global [@ipcc2021physical].

Finalmente, para este estudio, se analizarán los datos de temperatura media proporcionados por el IDEAM, correspondientes a la estación meteorológica 80222 de la Organización Meteorológica Mundial (WMO), ubicada en el Aeropuerto Internacional El Dorado (SKBO) en Bogotá. Estos datos fueron extraídos mediante la API gratuita de Meteostat en Python. Esta estación representa una fuente confiable y de alta calidad para el monitoreo climático a nivel local, ya que cuenta con registros continuos que permiten complementar el análisis histórico y el modelado climático, proporcionando una perspectiva más precisa del contexto urbano.


------------------------------------------------------------------------

<!--chapter:end:index.Rmd-->

# Medias Móviles, Rezagos y Descomposición de la Serie Temporal

Christian Vera, Yuli Deaquiz y Juan Rodríguez

26/04/2025

En primer lugar, se identifica la ventana temporal de las temperaturas registradas por este sensor, la cual comprende datos diarios desde el 1 de enero de 1975 hasta el 31 de marzo de 2025. No obstante, es importante señalar que el conjunto de datos incluye observaciones que se remontan hasta el año 1941, lo que proporciona una perspectiva histórica amplia. Sin embargo, diversos análisis indican que la calidad y confiabilidad de los registros mejora significativamente a partir de 1972, debido a que en los periodos anteriores se observa una alta frecuencia de valores atípicos y anomalías que podrían comprometer la precisión de cualquier análisis basado en dichas observaciones. Por esta razón, los datos previos a 1972 suelen utilizarse con precaución o ser excluidos de los estudios que requieren alta fiabilidad en las series temporales [@Temperatura_Confiable]. 

Teniendo en cuenta lo anterior, se realizaran distintos análisis temporales de la temperatura promedio de la ciudad de Bogotá. Para ello, se aplicarán técnicas de suavizamiento mediante el cálculo de promedios móviles, así como análisis de rezagos y de estacionalidad. Estas aproximaciones permitirán identificar y representar patrones, tendencias y ciclos a lo largo del tiempo.

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
```

En primer lugar se carga y verifica el tipo de datos del conjunto de datos seleccionado, garantizando que la fecha esté en formato correcto. 

En el siguiente enlace se puede apreciar el proceso de extracción mediante las API de meteostat y Openmeteo en Python.

[Notebook de descarga de datos en GitHub](https://github.com/christianveram/Series_de_tiempo/blob/main/extraccion/Descargar%20conjunto%20de%20datos.ipynb)

```{r, include=TRUE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

url <- "https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv"
datos <- read.csv(url)
datos$time <- as.Date(datos$time)

# Mostrar tipo datos
datos %>%
  select(time, tavg) %>%
  summarise(across(everything(), ~class(.))) %>%
  pivot_longer(everything(), names_to = "Columna", values_to = "Tipo de Dato") %>%
  kable(format = "html", 
        align = "c") %>%
  kable_styling(full_width = F, position = "center")

```


```{r,include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(zoo)
library(forecast)

datos_filtrados <- datos %>%
  mutate(fecha = as.Date(time)) %>%
  arrange(fecha)  %>%
  filter(fecha >= as.Date("1975-01-01"))

# 'tavg' a dos decimales
datos_filtrados <- datos_filtrados %>%
  mutate(tavg = round(tavg, 2))

```

## Promedios móviles (SMA de 7 y 30 días)

El promedio móvil simple (SMA) es una técnica de suavizamiento que consiste en calcular el promedio de un número fijo de observaciones consecutivas. Sirve para reducir el "ruido" en los datos y destacar patrones como tendencias o ciclos, ayudando en el análisis visual de series de tiempo antes de aplicar modelos más complejos.

Se calcularon dos promedios móviles simples (SMA) sobre la variable de temperatura promedio diaria (tavg), utilizando ventanas de 7 y 30 días respectivamente. Para ello, se aplicó la función rollmean, permitiendo un relleno de valores faltantes con NA presente el algunos días de la serie y alineando las medias móviles hacia la derecha. Luego, se construyó un gráfico de líneas que incluye la serie original de temperatura (en gris claro) y las dos curvas suavizadas correspondientes a los promedios móviles (en azul acero para 7 días y rojo oscuro para 30 días).

Esta gráfica permite observar la evolución suavizada de la temperatura a lo largo del tiempo, eliminando la variabilidad diaria que puede ocultar patrones generales. El promedio móvil de 7 días capta fluctuaciones semanales, mientras que el de 30 días refleja tendencias de más largo plazo. Al observar esta última, se evidencia una tendencia ascendente en la temperatura promedio, especialmente notable en las últimas décadas.


```{r,include=TRUE, message=FALSE, warning=FALSE,fig.align='center'}

library(tidyr)
library(dplyr)
library(ggplot2)

# Cálculo de medias móviles
datos_filtrados <- datos_filtrados %>%
  mutate(
    sma_7 = rollmean(tavg, k = 7, fill = NA, align = "right"),
    sma_30 = rollmean(tavg, k = 30, fill = NA, align = "right"))

# gráfica con ggplot
grafica <- ggplot(datos_filtrados, aes(x = fecha)) +
  geom_line(aes(y = tavg, color = "Temperatura Promedio"), size = 0.5) +
  geom_line(aes(y = sma_7, color = "Media Móvil 7 Días"), size = 0.5) + 
  geom_line(aes(y = sma_30, color = "Media Móvil 30 Días"), size = 0.5) +
  labs(title = "Temperatura promedio con medias móviles",
       x = "Fecha", y = "Temperatura promedio (°C)") +
  scale_color_manual(values = c("Temperatura Promedio" = "gray70",
                                "Media Móvil 7 Días" = "steelblue", 
                                "Media Móvil 30 Días" = "darkred")) +
  theme_minimal() +
  theme(legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5))

print(grafica)


```

## Rezagos (lags de 1, 7 y 30 días)

Un rezago (lag) en series de tiempo consiste en desplazar la serie hacia atrás en el tiempo para observar cómo los valores pasados afectan a los valores presentes o futuros. El análisis de los rezagos permite identificar autocorrelaciones, que son relaciones importantes para modelar y predecir series temporales.

Se generaron tres nuevas variables de rezago (lag_1, lag_7 y lag_30), que corresponden a la temperatura promedio registrada hace 1, 7 y 30 días respectivamente. La gráfica ilustra la relación entre la temperatura de un día y la del día anterior. Una correlación positiva sugiere la existencia de dependencia temporal en la serie, es decir, que los valores actuales están influenciados por los valores pasados

En este caso se observa una correlación positiva, lo que indica que la temperatura actual tiende a ser más alta cuando la temperatura en el pasado (ya sea hace 1, 7 o 30 días) también fue más alta. Sin embargo, la fuerza de esta correlación disminuye a medida que aumenta el lapso de tiempo, indicando que la temperatura de días más lejanos en el pasado tiene una menor capacidad predictiva sobre la temperatura del presente en comparación con la temperatura de días más recientes.


```{r,include=TRUE, message=FALSE, warning=FALSE,fig.align='center'}
library(tidyr)
library(dplyr)
library(ggplot2)

# rezagos
datos_filtrados <- datos_filtrados %>%
  mutate(
    lag_1 = lag(tavg, 1),
    lag_7 = lag(tavg, 7),
    lag_30 = lag(tavg, 30))

datos_filtrados_long <- datos_filtrados %>%
  gather(key = "lag", value = "lag_value", lag_1, lag_7, lag_30) %>%
  mutate(lag = factor(lag, levels = c("lag_1", "lag_7", "lag_30")))

# Crear la gráfica con ggplot usando facet_wrap
grafica <- ggplot(datos_filtrados_long, aes(x = lag_value, y = tavg)) +
  geom_point(alpha = 0.3, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "black", size = 0.5) +  # Línea más fina
  labs(title = "Relación entre temperatura actual y rezago de diferentes días",
       x = "Temperatura rezagada", y = "Temperatura actual") +
  facet_wrap(~lag, scales = "free") +  # subgráfica para cada lag
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))  

# Mostrar la gráfica
print(grafica)
```

## Descomposición STL.

La descomposición STL (Seasonal and Trend decomposition using Loess) es una técnica que separa una serie de tiempo en componentes de tendencia, estacionalidad y ruido. Utiliza un enfoque basado en suavizamiento local, que permite capturar patrones no lineales y estacionalidades que pueden cambiar con el tiempo, ofreciendo una interpretación más detallada de la serie.

Para analizar la estacionalidad y la tendencia de la serie, se imputaron valores faltantes de la variable tavg mediante interpolación lineal (na.approx). Luego, se transformó la serie en un objeto de tipo ts con frecuencia anual (365 observaciones por año). Se aplicó una descomposición STL (stl) que separa la serie en tendencia, estacionalidad y residuo.

La descomposición STL permite visualizar cómo se estructura la variabilidad de la temperatura promedio en sus componentes principales. La tendencia muestra los cambios a largo plazo en la serie, la estacionalidad revela los patrones cíclicos asociados a las distintas épocas del año, y el residuo indica las fluctuaciones irregulares no explicadas. Este análisis es importante para entender los comportamientos recurrentes y para preparar adecuadamente los datos para modelos de pronóstico.

En este caso se puede extraer lo siguiente: 

* La tendencia muestra un aumento gradual de la temperatura a lo largo del tiempo, especialmente notable a partir de aproximadamente el año 2000. 
* El componente estacional revela un patrón cíclico que se repite anualmente, lo que sugiere variaciones de temperatura relacionadas con las estaciones del año. 
* El residuo representa las fluctuaciones irregulares que no se explican ni por la tendencia ni por la estacionalidad, indicando la presencia de variabilidad aleatoria o eventos inusuales en los datos de temperatura. 


```{r,include=TRUE, message=FALSE, warning=FALSE,fig.align='center'}

# Cargar librerías necesarias
library(plotly)
library(zoo)
library(ggplot2)
library(lubridate)
library(forecast)

# Imputamos NA para asegurar continuidad 
datos_ts <- ts(na.approx(datos_filtrados$tavg, na.rm = FALSE),
               frequency = 365,
               start = c(year(min(datos_filtrados$fecha)), yday(min(datos_filtrados$fecha))))

# Descomposición STL
descomposicion <- stl(datos_ts, s.window = "periodic")

# Convertir el gráfico ggplot a interactivo con plotly
grafico_interactivo <- autoplot(descomposicion) +
  labs(
    title = "Descomposición de la serie de temperatura promedio",
    x = "Fecha",
    y = "Valor"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 12, color = "black"),  # Cambié el color del título
    axis.title = element_text(size = 11, color = "black"),  # Cambié el color de los títulos de los ejes
    strip.text = element_text(face = "bold", size = 11, color = "black"),  # Cambié el color del texto de las etiquetas
    panel.grid.minor = element_blank()
  ) +
  # Ajustar el grosor de las líneas y el color de la serie
  geom_line(size = 0.2, color = "blue") 

# Convertir el gráfico ggplot a un gráfico interactivo
ggplotly(grafico_interactivo)



```

En conjunto, el uso de estas tres herramientas proporcionan una base para comprender la dinámica de la serie de tiempo. Esta aproximación no solo facilita la detección de ciclos estacionales y tendencias ocultas, sino que también es relevante para diseñar modelos predictivos más robustos. La correcta interpretación de estos componentes permite tomar decisiones mejor informadas en contextos relacionados con el análisis climático o la planificación de recursos




<!--chapter:end:02-Cap2.Rmd-->

# Estacionariedad

## **Preprocesamiento y visualización.**

Christian Vera, Yuli Deaquiz y Juan Rodríguez

04/05/2025

Una serie temporal estacionaria es aquella cuyas propiedades no dependen del momento en que se observa .Por lo tanto, las series temporales con tendencias o con estacionalidad no son estacionarias: la tendencia y la estacionalidad afectarán el valor de la serie temporal en diferentes momentos. Una serie temporal estacionaria no presenta patrones predecibles a largo plazo.

Esto implica que si la serie es estacionaria, estaríamos prediciendo que las características estadísticas de nuestra serie de tiempo serán las mismas en el futuro como en el pasado.

Para poder comprobar si la serie es estacionaria se puede utilizar algunos métodos estadísticos, entre los más utilizados se encuentran la **prueba de Dickey-Fuller Aumentada (ADF) y la prueba de Kwiatkowski-Phillips-Schmidt-Shin (KPSS**). Para nuestro caso usamos las dos pruebas como se muestran a continuación:

```{r, include=TRUE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(lubridate)
library(zoo)
library(forecast)

url <- "https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv"
datos <- read.csv(url)
datos$time <- as.Date(datos$time)

datos_filtrados <- datos %>%
  mutate(fecha = as.Date(time)) %>%
  arrange(fecha)  %>%
  filter(fecha >= as.Date("1975-01-01"))

# 'tavg' a dos decimales
datos_filtrados <- datos_filtrados %>%
  mutate(tavg = round(tavg, 2))
```

**Prueba de Dickey-Fuller.**

```{r, include=TRUE, message=FALSE, warning=FALSE}
# Prueba de Dickey-Fuller
# Ho: La serie no presenta estacionariedad
# Ha: La serie presenta estacionariedad

## Prueba de Dickey-Fuller

# Ejecutar la prueba Dickey-Fuller
library(tseries)
library(knitr)
library(kableExtra)

# Ejecutar la prueba
adf_result <- adf.test(datos_filtrados$tavg)

# Crear tabla de resultados
adf_table <- data.frame(
  "Test Statistic" = round(adf_result$statistic, 4),
  "Lag Order" = adf_result$parameter,
  "p-value" = round(adf_result$p.value, 4),
  "Alternative" = as.character(adf_result$alternative),
  check.names = FALSE
)

# Mostrar tabla con kableExtra
kable(adf_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")



```

Con un p-valor de 0.01, se rechaza la hipótesis nula de no estacionariedad, lo que indica que la serie de la variable temperatura promedio es estacionaria. Esto implica que sus propiedades estadísticas, como la media y la varianza, se mantienen constantes en el tiempo y que la serie no presenta una tendencia sostenida.

**Prueba KPSS**

```{r, include=TRUE, message=FALSE, warning=FALSE}
# Prueba KPSS
# Ho: La serie es estacionaria
# Ha: La serie no es estacionaria

library(tseries)
library(knitr)
library(kableExtra)

kpss_result <- kpss.test(datos_filtrados$tavg)

# Crear tabla de resultados
kpss_table <- data.frame(
  "KPSS Statistic" = round(kpss_result$statistic, 3),
  "Truncation Lag Parameter" = kpss_result$parameter,
  "p-value" = round(kpss_result$p.value, 4),
  check.names = FALSE
)

# Mostrar tabla con numeración automática
kable(kpss_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )


```

El p-valor es 0.01. Dado que este valor es menor que el nivel de significancia de 0.05, se rechaza la hipótesis nula de estacionariedad. Esto indica que la serie temporal no es estacionaria en nivel, lo cual sugiere que presenta una tendencia sistemática a lo largo del tiempo, como un posible aumento progresivo en la temperatura promedio.

Con base en los resultados de las pruebas realizadas, se puede concluir que la serie es estacionaria en diferencias, según el test ADF, pero no lo es en tendencia, según el test KPSS. Por lo tanto, se recomienda llevar a cabo el proceso de diferenciación para lograr la estacionariedad de la serie.

## Diferenciación

La diferenciación es una técnica utilizada en el análisis de series temporales para hacer que una serie no estacionaria se vuelva estacionaria. Esto se logra calculando las diferencias entre valores consecutivos de la serie temporal. Así mismo, ayuda a eliminar las tendencias en los datos, haciendo que la serie sea estacionaria. Además, facilita el Modelado ya que al hacer que la serie sea estacionaria, se facilita la aplicación de modelos de series temporales como ARIMA.

Para la variable de temperatura promedio se aplicó una diferenciación de primer orden, la cual calcula la diferencia entre cada valor y el anterior en la serie temporal.

Posteriormente se realizó nuevamente los test estadísticos de comprobación de la estacionariedad.

**Dickey-Fuller Test (Diferenciación)**

```{r, include=TRUE, message=FALSE, warning=FALSE}

# Prueba de Dickey-Fuller
# Ho: La serie no presenta estacionariedad
# Ha: La serie presenta estacionariedad

## Prueba de Dickey-Fuller

estacionariedad=diff(datos_filtrados$tavg)
#adf.test(estacionariedad)

# Ejecutar la prueba Dickey-Fuller
library(tseries)
library(knitr)
library(kableExtra)

# Ejecutar la prueba
adf_result1 <- adf.test(estacionariedad)

# Crear tabla de resultados
adf_table <- data.frame(
  "Test Statistic" = round(adf_result1$statistic, 4),
  "Lag Order" = adf_result1$parameter,
  "p-value" = round(adf_result1$p.value, 4),
  "Alternative" = as.character(adf_result1$alternative),
  check.names = FALSE
)

# Mostrar tabla 
kable(adf_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")

```

En este caso el valor p de 0.01 indica que se puede rechazar la hipótesis nula de que la serie no es estacionaria, siendo menor al umbral de significancia 0.05.

**KPSS Test (Diferenciación).**

```{r, include=TRUE, message=FALSE, warning=FALSE}

# Prueba KPSS
# Ho: La serie es estacionaria
# Ha: La serie no es estacionaria
#kpss.test(estacionariedad)

library(tseries)
library(knitr)
library(kableExtra)

kpss_result2 <- kpss.test(estacionariedad)

# Crear tabla de resultados
kpss_table <- data.frame(
  "KPSS Statistic" = round(kpss_result2$statistic, 3),
  "Truncation Lag Parameter" = kpss_result2$parameter,
  "p-value" = round(kpss_result2$p.value, 4),
  check.names = FALSE)

# Mostrar tabla
kable(kpss_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")


```

En este caso, el test KPSS aplicado a la serie diferenciada da un valor p de 0.1, lo que sugiere que no hay suficiente evidencia para rechazar la hipótesis nula de estacionariedad en el nivel, indicando que la serie es estacionaria después de la diferenciación. En comparación con el test anterior, donde el valor p era 0.01, que indicaba que la serie no era estacionaria, esta diferencia sugiere que la diferenciación eliminó la tendencia y permitió que la serie se volviera estacionaria. Finalmente, se puede concluir en los dos test estadísticos con un nivel de confianza del 95% que la serie es estacionaria luego de aplicar la diferenciación.

```{r, include=TRUE, message=FALSE, warning=FALSE}
library(forecast)

par(mfrow = c(2, 2), mar = c(5, 5, 3, 1))

# ACF para estacionariedad
acf(estacionariedad, lag.max = 34, main = "ACF - Serie diferenciada")

# PACF para estacionariedad
pacf(estacionariedad, lag.max = 34, main = "PACF - Serie diferenciada")

# ACF para datos_filtrados$tavg
acf(datos_filtrados$tavg, lag.max = 34, main = "ACF - Serie Original")

# PACF para datos_filtrados$tavg
pacf(datos_filtrados$tavg, lag.max = 34, main = "PACF - Serie Original")

```

**Figura 3.1** Análisis de Autocorrelación (ACF y PACF) de la serie de temperatura promedio de la ciudad de Bogotá DC.

A partir de la **Figura 3.1** se puede extraer lo siguiente:

**ACF - Serie diferenciada:**

Presenta un pico negativo significativo en el Lag 1, lo que indica una autocorrelación negativa inmediata entre los valores consecutivos después de la diferenciación. Los rezagos posteriores se encuentran dentro de los límites de confianza, lo que sugiere ausencia de autocorrelación significativa en los siguientes periodos, lo cual es un indicativo de una serie estacionaria.

**PACF - Serie diferenciada:**

Muestra un pico negativo significativo en el Lag 1, mostrando una fuerte correlación parcial negativa con el primer rezago. Las barras de los rezagos posteriores se mantienen dentro de los límites de confianza, indicando que no hay efectos significativos más allá del primer rezago. Esto sugiere que la serie ha alcanzado estabilidad en sus propiedades estadísticas.

**ACF - Serie Original:**

Se observa una reducción lenta de las autocorrelaciones, con barras que permanecen fuera de los límites de confianza en varios rezagos, lo que indica una dependencia temporal y sugiere visualmente que la serie no es estacionaria. Sin embargo, los resultados del test ADF aplicado a la serie original indican que se puede considerar estacionaria desde el punto de vista estadístico

**PACF - Serie Original:**

Presenta un pico significativo en el Lag 1 (positivo), lo que indica una fuerte correlación parcial con el primer rezago. Aunque los valores disminuyen rápidamente, algunos rezagos posteriores muestran ligeras significancias, reforzando la idea de no estacionariedad en la serie original y sugiere la necesidad de aplicar una diferenciación para estabilizarla.

En resumen, el análisis mostró que la serie de temperatura promedio en Bogotá no es estacionaria al inicio debido a una tendencia, pero al aplicar una diferenciación de primer orden se logra estabilizar. Esto es clave para poder aplicar modelos como ARIMA y hacer predicciones más precisas y confiables.

<!--chapter:end:03-Cap3.Rmd-->

# Holt-Winters.

Christian Vera, Yuli Deaquiz y Juan Rodríguez

10/05/2025

El modelo de Holt-Winters, permite analizar series de tiempo univariantes que contienen factores de tendencia y/o estacionalidad, involucrando un enfoque de suavización exponencial con métodos analíticos y patrones aditivos y multiplicativos.

Es un método mejorado para calcular pronósticos cuando los datos muestran una tendencia y además estacionalidad, por lo cual se incorporan 3 constantes, que son α y β, según la metodología de Holt el cual tiene encuenta el nivel de los datos y su tendencia, agregando además γ, el cual incluye la estacionalidad, cuyos valores también deben estar entre cero y la unidad.

Para este ejercicio se dividio la base de datos en una base de entrenamiento y un test de prueba de la siguiente forma:

-   Base de entrenamiento: del periodo de 1975 a 2021.

-   Base de prueba: periodo de 2022 en adelante.

```{r, include=TRUE, message=FALSE, warning=FALSE}

# Cargar paquetes necesarios
library(tidyverse)
library(lubridate)
library(forecast)
library(kableExtra)

# 1. Cargar y preparar los datos
url <- "https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv"
datos <- read.csv(url)
datos$time <- as.Date(datos$time)

datos_filtrados <- datos %>%
  mutate(fecha = as.Date(time),
         tavg = round(tavg, 2)) %>%
  filter(fecha >= as.Date("1975-01-01")) %>%
  arrange(fecha)

# 2. Agregar datos por mes (promedio mensual)
datos_mensuales <- datos_filtrados %>%
  mutate(anio_mes = floor_date(fecha, "month")) %>%
  group_by(anio_mes) %>%
  summarise(tavg = mean(tavg, na.rm = TRUE)) %>%
  ungroup()

# 3. Convertir a serie temporal
ts_temp <- ts(datos_mensuales$tavg,
              start = c(year(min(datos_mensuales$anio_mes)), month(min(datos_mensuales$anio_mes))),
              frequency = 12)

# 4. Separar en conjunto de entrenamiento (hasta 2021) y prueba (desde 2022)
ts_train <- window(ts_temp, end = c(2021, 12))
ts_test  <- window(ts_temp, start = c(2022, 1))

# 5. Ajustar modelo Holt-Winters clásico
modelo_hw <- HoltWinters(ts_train)

```

## Ajuste Holt-Winters.

```{r, include=TRUE, message=FALSE, warning=FALSE}

# 6. Graficar la serie completa con ajuste
# Crear una serie para el ajuste de Holt-Winters
ajuste_completo <- ts(fitted(modelo_hw)[,1], start = start(ts_temp), frequency = 12)

# Graficar la serie original con el ajuste
plot(ts_temp, main = "Serie completa con ajuste Holt-Winters",
     col = "blue", lwd = 2, ylab = "Temperatura", xlab = "Tiempo")
lines(ajuste_completo, col = "red", lwd = 1.5)
legend("topright", legend = c("Serie completa", "Ajuste Holt-Winters"),
       col = c("blue", "red"), lwd = 2)


```

**Figura 4.1.** Serie temporal método Hold-Winters para la temperatura promedio de la ciudad Bogotá DC.

Se puede observar en la figura 4.1 que el modelo Hold-Winters muestra un buen ajuste de la variable, ya que la linea roja (modelo de Hold-Winters) es cercana a la serie original (linea azul), sin embargo, no puede captar todas las fluctuaciones menores que puede asociarse a datos atipicos en algunos periodos de tiempo, que pueden estar asociados al fenómeno del niño y la niña.

Además, este modelo esta diseñado para capturar patrones de tendencia y regularidad que pueden verse influenciados en este caso por fenomenos climáticos.

## Pronóstico Holt-Winters (12 meses)

```{r, include=TRUE, message=FALSE, warning=FALSE}
# 7. Pronosticar 36 meses
pronostico <- forecast(modelo_hw, h = 12)

# 8. Graficar el pronóstico
plot(pronostico, main = "Pronóstico Holt-Winters (12 meses)",
     xlab = "Tiempo", ylab = "Temperatura")
```

**Figura 4.2.** Pronóstico Holt-Winter para la temperatura promedio de la ciudad de Bogotá DC.

En la figura 4.2 se observa con una confiabilidad del 95% representada en las lineas grises, que la temperatura promedio oscilará entre 14 a 15 °C para los siguientes 12 meses entre 2022-1 a 2022-12, sobre los cuales se realizó la evaluación del modelo.

## Métricas de desempeño.

```{r, include=TRUE, message=FALSE, warning=FALSE}

# 9. Calcular métricas de evaluación sobre el conjunto de prueba
metricas <- accuracy(pronostico, ts_test)
metricas_df <- as.data.frame(metricas)[2, c("ME", "RMSE", "MAE", "MAPE")]

# Convertir a data frame con nombres descriptivos
metricas_df <- data.frame(
  Métrica = c("Error Medio (ME)", 
              "Raíz del Error Cuadrático Medio (RMSE)",
              "Error Absoluto Medio (MAE)", 
              "Error Porcentual Absoluto Medio (MAPE)"),
  Valor = unlist(metricas_df)
)

# 10. Mostrar tabla con el mismo estilo que adf_table
kable(metricas_df, align = "c", row.names = FALSE) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )
```

En relación a la tabla anterior, que reporta las métricas del modelo se puede inferir:

-   **Error Medio:** con un valor de -0.77 indica que el modelo subestima la temperatura en -0.77°C.

-   **Raíz del Cudratíco medio de los errores:** con un valor 0.84, esto significa que, en promedio, la desviación de las predicciones del modelo respecto a los valores reales es aproximadamente 0.84 unidades. Un RMSE más bajo indica un mejor ajuste del modelo a los datos, ya que sugiere que los errores de predicción son menores.

-   **Error Absoluto Medio:** Esto significa que, en promedio, las predicciones del modelo se desvían de los valores reales en aproximadamente 0.77 unidades. A diferencia del RMSE, el MAE no eleva al cuadrado las diferencias, lo que significa que no es tan sensible a los valores atípicos.

-   **Error Porcentual Absoluto medio:** En terminos relativo las predicciones del modelo estan un 5.7% por encima o por debajo del valor real.

Se puede concluir que la predicción a partir del método Holt-Winter tiene un desempeño adecuado para la variable de temperatura promedio, aunque es suceptible de mejoras para reducir el sesgo y minimizar los errores.

<!--chapter:end:04-Cap4.Rmd-->

# Metodología Box Jenkins

La metodología Box-Jenkins es una herramienta muy útil cuando queremos entender y predecir el comportamiento de una serie de datos a lo largo del tiempo. Se basa en modelos ARIMA, que permiten analizar si hay patrones repetitivos, tendencias o comportamientos aleatorios en los datos. El proceso consiste en tres pasos,identificar el tipo de modelo que mejor se ajusta, estimar sus parámetros y luego revisar si los errores del modelo (los residuos) no tienen patrones, es decir, que sean impredecibles.

En este caso, vamos a aplicar esta metodología a la temperatura promedio mensual de Bogotá desde 1975. Aunque el clima de la ciudad tiende a ser bastante estable por su ubicación y altitud, los datos históricos pueden mostrar cambios sutiles o incluso señales del cambio climático. Con esta técnica, podemos ver cómo ha cambiado la temperatura a lo largo del tiempo y hacer pronósticos que podrían ser útiles para temas como la agricultura, la salud o la planificación urbana.


```{r, include=TRUE, message=FALSE, warning=FALSE}
# Librerías
library(tidyverse)
library(forecast)
library(tseries)
library(knitr)
library(kableExtra)
library(lubridate)

```



## Cargar y preparar dato

```{r, include=TRUE, message=FALSE, warning=FALSE}

# Cargar datos
url <- "https://raw.githubusercontent.com/christianveram/Series_de_tiempo/refs/heads/main/bases/temperaturas_final.csv"
datos <- read.csv(url)
datos$time <- as.Date(datos$time)

# Filtrar desde 1975 y redondear tavg
datos_filtrados <- datos %>%
  mutate(fecha = as.Date(time),
         tavg = round(tavg, 2)) %>%
  filter(fecha >= as.Date("1975-01-01")) %>%
  arrange(fecha)


```


## Visualización inicial de la serie


```{r, include=TRUE, message=FALSE, warning=FALSE}
ggplot(datos_filtrados, aes(x = fecha, y = tavg)) +
  geom_line(color = "#2C3E50") +
  labs(title = "Serie de Temperatura Promedio Diaria",
       x = "Fecha",
       y = "Temperatura (°C)") +
  theme_minimal(base_size = 13)
```



## Transformación a serie temporal mensual

En primer lugar, se agrupan los datos por mes y se calcula el promedio mensual de temperatura (tavg). Luego, se crea una serie temporal (ts_mensual) con esos valores, indicando que comienza en enero de 1975 y tiene una frecuencia mensual.

```{r, include=TRUE, message=FALSE, warning=FALSE}
datos_mensual <- datos_filtrados %>%
  mutate(mes = floor_date(fecha, "month")) %>%
  group_by(mes) %>%
  summarise(tavg = mean(tavg, na.rm = TRUE))

ts_mensual <- ts(datos_mensual$tavg, start = c(1975, 1), frequency = 12)

autoplot(ts_mensual, series = "Temperatura") +
  ggtitle("Temperatura Promedio Mensual") +
  ylab("Temperatura (°C)") +
  xlab("Año") +
  theme_minimal() +
  scale_color_manual(values = c("Temperatura" = "#1F77B4"))

```

## Prueba de Estacionariedad (ADF)

La prueba de Dickey-Fuller aumentada (ADF) es una prueba estadística que se utiliza para determinar si una serie temporal es estacionaria, es decir, si sus propiedades estadísticas como la media y la varianza se mantienen constantes en el tiempo. En esta prueba, la hipótesis nula (H₀) establece que la serie no es estacionaria, mientras que la hipótesis alternativa (H₁) afirma que sí lo es. En el resultado obtenido, el valor del estadístico fue -14.5464 y el valor-p fue 0.01, lo que significa que se rechaza la hipótesis nula al nivel de significancia del 5%. Por lo tanto, se concluye que la serie de temperatura promedio (tavg) es estacionaria y puede ser utilizada en modelos que requieren esta condición, como los modelos ARIMA.


```{r, include=TRUE, message=FALSE, warning=FALSE}
## Prueba de Dickey-Fuller

# Prueba de Dickey-Fuller
# Ho: La serie no presenta estacionariedad
# Ha: La serie presenta estacionariedad

# Ejecutar la prueba Dickey-Fuller
library(tseries)
library(knitr)
library(kableExtra)

# Ejecutar la prueba
adf_result <- adf.test(datos_filtrados$tavg)

# Crear tabla de resultados
adf_table <- data.frame(
  "Test Statistic" = round(adf_result$statistic, 4),
  "Lag Order" = adf_result$parameter,
  "p-value" = round(adf_result$p.value, 4),
  "Alternative" = as.character(adf_result$alternative),
  check.names = FALSE
)

# Mostrar tabla con kableExtra
kable(adf_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")


```

## Prueba KPSS

La prueba KPSS es una prueba estadística utilizada para evaluar si una serie temporal es estacionaria en nivel. A diferencia de la prueba ADF, en la KPSS la hipótesis nula (H₀) establece que la serie es estacionaria, mientras que la hipótesis alternativa (H₁) plantea que no es estacionaria. En el resultado mostrado, el estadístico KPSS fue 34.079 con un valor-p de 0.01. Como el valor-p es menor a 0.05, se rechaza la hipótesis nula, lo que indica que la serie de temperatura promedio (tavg) no es estacionaria según esta prueba. Este resultado contradice la prueba ADF, por lo cual es pertinente realizar una diferenciación para confirmar el supuesto de estacionariedad del modelo ARIMA.


```{r, include=TRUE, message=FALSE, warning=FALSE}
# Prueba KPSS
# Ho: La serie es estacionaria
# Ha: La serie no es estacionaria

library(tseries)
library(knitr)
library(kableExtra)

kpss_result <- kpss.test(datos_filtrados$tavg)

# Crear tabla de resultados
kpss_table <- data.frame(
  "KPSS Statistic" = round(kpss_result$statistic, 3),
  "Truncation Lag Parameter" = kpss_result$parameter,
  "p-value" = round(kpss_result$p.value, 4),
  check.names = FALSE
)

# Mostrar tabla con numeración automática
kable(kpss_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  )


```



## Diferenciación.

Se aplica una primera diferencia a la serie temporal mensual de temperatura promedio con el objetivo de eliminar tendencias y hacerla estacionaria, es decir, que sus propiedades estadísticas no cambien con el tiempo. Luego, se vuelve a realizar las dos pruebas sobre la serie diferenciada. Los resultados muestran que en la prueba ADF el valor-p es 0.01, lo que lleva a rechazar la hipótesis nula y concluir que la serie diferenciada es estacionaria. Por su parte, en la prueba KPSS el valor-p es 0.1, por lo que no se rechaza la hipótesis nula y se concluye que la serie es estacionaria, lo cual es adecuado para el modelo ARIMA que requiere esta propiedad.


```{r, include=TRUE, message=FALSE, warning=FALSE}
#Primera diferencia
ts_diff1 <- diff(ts_mensual)

### Nuevas pruebas
adf_diff <- adf.test(ts_diff1)
kpss_diff <- kpss.test(ts_diff1)

### Tabla ADF sobre primera diferencia
adf_table <- tibble(
  Estadístico_ADF = round(adf_diff$statistic, 4),
  Valor_P = round(adf_diff$p.value, 4),
  Hipótesis_nula = "La serie NO es estacionaria",
  Decisión = ifelse(adf_diff$p.value < 0.05,
                    "Rechazada: la serie ES estacionaria",
                    "No rechazada: la serie NO es estacionaria")
)

# Mostrar tabla con kableExtra Prueba ADF
kable(adf_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")

```

```{r, include=TRUE, message=FALSE, warning=FALSE}
# Tabla KPSS sobre primera diferencia
kpss_table <- tibble(
  Estadístico_KPSS = round(kpss_diff$statistic, 4),
  Valor_P = kpss_diff$p.value,
  Hipótesis_nula = "La serie ES estacionaria",
  Decisión = ifelse(kpss_diff$p.value < 0.05,
                    "Rechazada: la serie NO es estacionaria",
                    "No rechazada: la serie ES estacionaria")
)

# Mostrar tabla con kableExtra Prueba KPSS
kable(kpss_table, align = "c") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center")

```



## ACF y PACF

```{r, include=TRUE, message=FALSE, warning=FALSE,fig.width=10, fig.height=4}
library(ggplot2)
library(forecast)
library(patchwork)

p1 <- ggAcf(ts_diff1) + 
  theme_minimal() + 
  ggtitle("ACF de la serie diferenciada") +
  theme(plot.title = element_text(hjust = 0.5))

p2 <- ggPacf(ts_diff1) + 
  theme_minimal() + 
  ggtitle("PACF de la serie diferenciada") +
  theme(plot.title = element_text(hjust = 0.5))

p1 + p2 + plot_layout(widths = c(1.5, 1.5))

```

Los gráficos muestran el análisis de la autocorrelación (ACF) y la autocorrelación parcial (PACF) de la serie temporal después de aplicar la primera diferencia, lo cual ayuda a identificar la estructura de dependencia entre los valores en diferentes rezagos (lags). A continuación se presentan los aspectos mas relevantes de cada uno: 

* *ACF:*, observamos que la mayoría de los valores caen dentro de las bandas de confianza (líneas azules), lo que indica que no hay una autocorrelación significativa persistente. Esto sugiere que la serie ya no tiene una tendencia clara ni patrones de dependencia fuertes después de ser diferenciada.

* *PACF*: se observan algunos picos significativos en los primeros rezagos, pero también la mayoría están dentro de las bandas de confianza. Esto puede indicar que hay ciertas relaciones directas entre la serie actual y algunos rezagos específicos, pero en general, la estructura de dependencia ha disminuido.



## Ajuste del modelo ARIMA. 

Se utiliza la función auto.arima del paquete forecast para ajustar automáticamente un modelo ARIMA, buscando los valores óptimos de tres parámetros principales: p (el orden de la parte autorregresiva), d (el número de diferencias necesarias para que la serie sea estacionaria) y q (el orden de la media móvil). Además, si la serie temporal presenta estacionalidad, la función también ajusta los parámetros estacionales correspondientes: P, D y Q, que representan patrones repetitivos en intervalos específicos, como meses o trimestres.

```{r, include=TRUE, message=FALSE, warning=FALSE}
modelo <- auto.arima(ts_mensual, seasonal = TRUE, stepwise = FALSE, approximation = FALSE)
summary(modelo)
```

El modelo ajustado a la serie ts_mensual fue un ARIMA(2,1,1)(2,0,0)[12], lo que significa que se aplicó una diferenciación no estacional de orden 1 (d = 1) para estabilizar la media de la serie, junto con dos términos autorregresivos (p = 2) y uno de media móvil (q = 1). Además, se incluyeron componentes estacionales autorregresivos (P = 2) sin diferenciación estacional (D = 0) ni términos de media móvil estacional (Q = 0), con una periodicidad de 12, lo que indica que se trata de datos mensuales. Los coeficientes estimados para cada parámetro son estadísticamente significativos, como lo sugieren sus errores estándar relativamente bajos. Esto indica que los componentes del modelo capturan adecuadamente la estructura temporal de la serie.

En cuanto a la calidad del modelo, la varianza del error fue de 0.1513, lo que indica que los errores de predicción no son muy grandes.Por otro lado, las métricas de error como el RMSE (0.387) y el MAPE (2.19%) muestran que el modelo predice con buena precisión. Finalmente, la autocorrelación del residuo en el primer rezago es muy cercana a cero (-0.028), lo que sugiere que no quedan patrones importantes sin capturar, confirmando que el modelo se ajusta bien a la serie temporal.

## Diagnóstico del modelo

```{r, include=TRUE, message=FALSE, warning=FALSE}
checkresiduals(modelo)
```
El test de Ljung-Box aplicado a los residuos del modelo ARIMA(2,1,1)(2,0,0)[12] tiene un p-valor de 0.00103, lo cual indica que hay evidencia de autocorrelación en los residuos. En otras palabras, el modelo no logra capturar completamente toda la estructura temporal de la serie, ya que los residuos aún muestran patrones. 

Adicionalmente, el gráfico muestra los residuos del modelo ARIMA(2,1,1)(2,0,0)[12],permitiendo evaluar si estos se comportan como ruido blanco, es decir, si no presentan patrones visibles. Aunque visualmente los residuos parecen centrarse en torno a cero y distribuidos de forma aproximadamente normal, el gráfico de autocorrelación (ACF) revela que hay varios rezagos que exceden los límites de significancia, lo cual confirma la presencia de autocorrelación presentada en el test Ljung-Box.


## Pronóstico

A continuación se presenta el pronóstico con base en el modelo ARIMA(2,1,1)(2,0,0)[12] ajustado a la serie de temperatura mensual. El gráfico muestra la proyección para los próximos 24 meses, incluyendo tanto los valores estimados como los intervalos de confianza que muestran la incentidumbre presentada en cada predicción.

```{r, include=TRUE, message=FALSE, warning=FALSE}

forecast_temp <- forecast(modelo, h = 24)

autoplot(forecast_temp) +
  labs(
    title = "Pronóstico de Temperatura para 2 Años",
    x = "Año", 
    y = "Temperatura (°C)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```




<!--chapter:end:05-cap5.Rmd-->

`r if (knitr:::is_html_output()) '
# Referencias {-}
'`

<!--chapter:end:05-referencias.RMD-->

