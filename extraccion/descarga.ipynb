{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción del conjunto de datos\n",
        "\n",
        "Se instala la librería de Meteostar y se verifican las estaciones mas cercanas a la ciudad de Bogotá."
      ],
      "metadata": {
        "id": "s8KtB6tPvwh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install meteostat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHp8J4MdF33d",
        "outputId": "bc750b51-a7f6-4a21-d0a1-4156b8971819"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: meteostat in /usr/local/lib/python3.11/dist-packages (1.6.8)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.11/dist-packages (from meteostat) (2.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from meteostat) (2025.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from meteostat) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1->meteostat) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1->meteostat) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1->meteostat) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from meteostat import Stations\n",
        "import pandas as pd\n",
        "\n",
        "# Crear el objeto Stations\n",
        "stations = Stations()\n",
        "\n",
        "# Filtrar estaciones cercanas a Bogotá (lat: 4.61, lon: -74.08)\n",
        "stations = stations.nearby(4.61, -74.08)\n",
        "\n",
        "# Obtener las 10 estaciones más cercanas\n",
        "stations_df = stations.fetch(10)\n",
        "\n",
        "# Seleccionar columnas clave para visualizar mejor\n",
        "cols = ['name', 'country', 'region', 'latitude', 'longitude', 'elevation']\n",
        "stations_pretty = stations_df[cols]\n",
        "\n",
        "# Mostrar tabla ordenada y legible\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(stations_pretty)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf318HPTFfmh",
        "outputId": "744059d5-00a9-40e3-d0ab-7cf3e63efa2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             name country region  latitude  longitude  elevation\n",
            "id                                                                              \n",
            "80222           Bogota / Eldorado      CO    CAM    4.7167   -74.1500     2547.0\n",
            "SKGY0       Guaymaral / Quirotama      CO    BOL    4.8123   -74.0649     2557.0\n",
            "80234  Villavicencio / Vanguardia      CO    MET    4.1667   -73.6167      423.0\n",
            "69377   Apiay (TMQ-53) / La Palma      CO    MET    4.0700   -73.5500      378.0\n",
            "80219   Girardot / Santiago Villa      CO    CAM    4.2833   -74.8000      286.0\n",
            "SKQU0      Mariquita / San Rafael      CO    TOL    5.2167   -74.8833      467.0\n",
            "80214            Ibague / Perales      CO    TOL    4.4333   -75.1500      928.0\n",
            "80149        Manizales / La Nubia      CO    CAL    5.0333   -75.4667     2080.0\n",
            "80211           Armenia / El Eden      CO    QUI    4.5000   -75.7167     1204.0\n",
            "80210          Pereira / Matecana      CO    RIS    4.8167   -75.7333     1342.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from meteostat import Daily\n",
        "from datetime import datetime\n",
        "\n",
        "# Estación con histórico largo (ejemplo)\n",
        "station_id = '80222'\n",
        "\n",
        "start = datetime(1900, 1, 1)\n",
        "end = datetime.now()\n",
        "\n",
        "# Descargar datos diarios\n",
        "data = Daily(station_id, start, end)\n",
        "df1 = data.fetch()\n",
        "\n",
        "# Guardar en CSV\n",
        "df1.to_csv(f'datos_meteorologicos_{station_id}.csv', index=True)\n",
        "print(df1.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "9QUCL02VGavI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5222bb44-6835-49d3-e1b1-d5c17e6049f9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            tavg  tmin  tmax  prcp  snow  wdir  wspd  wpgt  pres  tsun\n",
            "time                                                                  \n",
            "1941-03-02  17.1   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
            "1941-03-12  16.9   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
            "1941-03-13  19.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
            "1941-03-16  16.5   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n",
            "1941-03-19  17.3   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En segundo lugar, se utiliza la librería Open-Meteo para imputar los valores faltantes en la serie de tiempo, aprovechando datos horarios disponibles que permiten calcular promedios diarios y así completar de manera más precisa las observaciones ausentes en el conjunto de datos original."
      ],
      "metadata": {
        "id": "K-zrykHv_ycA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openmeteo-requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmRykt-DlE9A",
        "outputId": "35742521-56e0-4cba-d6f2-b54cf93abeb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openmeteo-requests\n",
            "  Downloading openmeteo_requests-1.4.0-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting openmeteo-sdk>=1.4.0 (from openmeteo-requests)\n",
            "  Downloading openmeteo_sdk-1.20.0-py3-none-any.whl.metadata (935 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openmeteo-requests) (2.32.3)\n",
            "Requirement already satisfied: flatbuffers==25.2.10 in /usr/local/lib/python3.11/dist-packages (from openmeteo-sdk>=1.4.0->openmeteo-requests) (25.2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openmeteo-requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->openmeteo-requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openmeteo-requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->openmeteo-requests) (2025.1.31)\n",
            "Downloading openmeteo_requests-1.4.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading openmeteo_sdk-1.20.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: openmeteo-sdk, openmeteo-requests\n",
            "Successfully installed openmeteo-requests-1.4.0 openmeteo-sdk-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests-cache retry-requests numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI1TuYNElIMN",
        "outputId": "6fc15e76-e3ac-4db9-9f3a-a2bbca019d95"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting requests-cache\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting retry-requests\n",
            "  Downloading retry_requests-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (25.3.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.22 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (2.32.3)\n",
            "Collecting url-normalize>=1.4 (from requests-cache)\n",
            "  Downloading url_normalize-2.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.5 in /usr/local/lib/python3.11/dist-packages (from requests-cache) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22->requests-cache) (2025.1.31)\n",
            "Downloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry_requests-2.0.0-py3-none-any.whl (15 kB)\n",
            "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-2.2.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: url-normalize, cattrs, retry-requests, requests-cache\n",
            "Successfully installed cattrs-24.1.3 requests-cache-1.2.1 retry-requests-2.0.0 url-normalize-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "import pandas as pd\n",
        "from retry_requests import retry\n",
        "\n",
        "# Setup the Open-Meteo API client with cache and retry on error\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
        "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "# Make sure all required weather variables are listed here\n",
        "# The order of variables in hourly or daily is important to assign them correctly below\n",
        "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "params = {\n",
        "    \"latitude\": 4.6097,\n",
        "    \"longitude\": -74.0817,\n",
        "    \"start_date\": \"1972-01-01\",\n",
        "    \"end_date\": \"1973-12-31\",\n",
        "    \"hourly\": \"temperature_2m\"\n",
        "}\n",
        "responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "# Process first location. Add a for-loop for multiple locations or weather models\n",
        "response = responses[0]\n",
        "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
        "print(f\"Elevation {response.Elevation()} m asl\")\n",
        "print(f\"Timezone {response.Timezone()}{response.TimezoneAbbreviation()}\")\n",
        "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
        "\n",
        "# Process hourly data. The order of variables needs to be the same as requested.\n",
        "hourly = response.Hourly()\n",
        "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "\n",
        "hourly_data = {\"date\": pd.date_range(\n",
        "    start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
        "    end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
        "    freq = pd.Timedelta(seconds = hourly.Interval()),\n",
        "    inclusive = \"left\"\n",
        ")}\n",
        "\n",
        "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
        "\n",
        "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
        "\n",
        "# Guardar el DataFrame en un archivo CSV\n",
        "hourly_dataframe.to_csv('temperature_data_1972_1973.csv', index=False)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "print(hourly_dataframe)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5ySPZ-NlD08",
        "outputId": "725e5d0c-7541-4784-f7c6-cf12927b8215"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates 4.604569435119629°N -73.97866821289062°E\n",
            "Elevation 2582.0 m asl\n",
            "Timezone NoneNone\n",
            "Timezone difference to GMT+0 0 s\n",
            "                           date  temperature_2m\n",
            "0     1972-01-01 00:00:00+00:00       12.859000\n",
            "1     1972-01-01 01:00:00+00:00       12.509001\n",
            "2     1972-01-01 02:00:00+00:00       12.159000\n",
            "3     1972-01-01 03:00:00+00:00       11.859000\n",
            "4     1972-01-01 04:00:00+00:00       11.859000\n",
            "...                         ...             ...\n",
            "17539 1973-12-31 19:00:00+00:00       15.609000\n",
            "17540 1973-12-31 20:00:00+00:00       15.309000\n",
            "17541 1973-12-31 21:00:00+00:00       14.209001\n",
            "17542 1973-12-31 22:00:00+00:00       13.559000\n",
            "17543 1973-12-31 23:00:00+00:00       11.609000\n",
            "\n",
            "[17544 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openmeteo_requests\n",
        "import requests_cache\n",
        "import pandas as pd\n",
        "from retry_requests import retry\n",
        "\n",
        "# Setup del cliente de Open-Meteo con caché y reintentos automáticos\n",
        "cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
        "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
        "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
        "\n",
        "# Parámetros para la consulta a la API de Open-Meteo\n",
        "url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
        "params = {\n",
        "    \"latitude\": 4.6097,\n",
        "    \"longitude\": -74.0817,\n",
        "    \"start_date\": \"1940-01-01\",\n",
        "    \"end_date\": \"2025-03-31\",\n",
        "    \"hourly\": \"temperature_2m\"\n",
        "}\n",
        "responses = openmeteo.weather_api(url, params=params)\n",
        "\n",
        "# Procesar la respuesta para una sola ubicación\n",
        "response = responses[0]\n",
        "print(f\"Coordinates {response.Latitude()}°N {response.Longitude()}°E\")\n",
        "print(f\"Elevation {response.Elevation()} m asl\")\n",
        "print(f\"Timezone {response.Timezone()}{response.TimezoneAbbreviation()}\")\n",
        "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")\n",
        "\n",
        "# Extraer datos horarios\n",
        "hourly = response.Hourly()\n",
        "hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
        "\n",
        "# Construir DataFrame con datos horarios\n",
        "hourly_data = {\"date\": pd.date_range(\n",
        "    start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
        "    end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
        "    freq = pd.Timedelta(seconds = hourly.Interval()),\n",
        "    inclusive = \"left\"\n",
        ")}\n",
        "hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
        "hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
        "\n",
        "# Guardar el DataFrame horario\n",
        "hourly_dataframe.to_csv('temperature_data_1972_1973.csv', index=False)\n",
        "print(\"Datos horarios guardados en 'temperature_data_1972_1973.csv'\")\n",
        "print(hourly_dataframe.head())\n",
        "\n",
        "# Calcular el promedio diario de temperatura\n",
        "hourly_dataframe[\"date_only\"] = hourly_dataframe[\"date\"].dt.date\n",
        "daily_avg_temperature = hourly_dataframe.groupby(\"date_only\")[\"temperature_2m\"].mean().reset_index()\n",
        "daily_avg_temperature.columns = [\"date\", \"avg_temperature_2m\"]\n",
        "\n",
        "# Guardar el DataFrame diario\n",
        "daily_avg_temperature.to_csv(\"Promedio_openmeteo.csv\", index=False)\n",
        "print(\"Promedio diario de temperatura guardado en 'daily_avg_temperature_1972_1973.csv'\")\n",
        "print(daily_avg_temperature.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aokvzjYBxoh",
        "outputId": "61c56476-7bc5-40f0-ff09-e0cd79d314bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coordinates 4.604569435119629°N -73.97866821289062°E\n",
            "Elevation 2582.0 m asl\n",
            "Timezone NoneNone\n",
            "Timezone difference to GMT+0 0 s\n",
            "Datos horarios guardados en 'temperature_data_1972_1973.csv'\n",
            "                       date  temperature_2m\n",
            "0 1940-01-01 00:00:00+00:00       11.667000\n",
            "1 1940-01-01 01:00:00+00:00       11.516999\n",
            "2 1940-01-01 02:00:00+00:00       11.117000\n",
            "3 1940-01-01 03:00:00+00:00       11.266999\n",
            "4 1940-01-01 04:00:00+00:00       10.816999\n",
            "Promedio diario de temperatura guardado en 'daily_avg_temperature_1972_1973.csv'\n",
            "         date  avg_temperature_2m\n",
            "0  1940-01-01           12.314916\n",
            "1  1940-01-02           12.083667\n",
            "2  1940-01-03           12.000333\n",
            "3  1940-01-04           11.898250\n",
            "4  1940-01-05           12.131583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Columnas del DataFrame df1:\")\n",
        "print(df1.columns)\n",
        "\n",
        "missing_tavg = df1['tavg'].isnull().sum()\n",
        "print(f\"\\nCantidad de valores faltantes en la columna 'tavg' de df1: {missing_tavg}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_II2hBJn_KT",
        "outputId": "6f072376-ba9a-4aa2-dea7-30f0bd4f9580"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas del DataFrame df1:\n",
            "Index(['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun'], dtype='object')\n",
            "\n",
            "Cantidad de valores faltantes en la columna 'tavg' de df1: 492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df1.reset_index()\n",
        "\n",
        "print(\"Columnas del DataFrame stations_pretty:\")\n",
        "print(stations_pretty.columns)\n",
        "\n",
        "print(\"\\nColumnas del DataFrame df1:\")\n",
        "print(df1.columns)\n",
        "\n",
        "print(\"\\nColumnas del DataFrame hourly_dataframe:\")\n",
        "print(hourly_dataframe.columns)\n",
        "daily_avg_temperature = daily_avg_temperature.rename(columns={'date': 'time'})\n",
        "\n",
        "print(\"\\nColumnas del DataFrame daily_avg_temperature:\")\n",
        "daily_avg_temperature.columns\n",
        "\n",
        "# Eliminar la columna que es de tipo int64\n",
        "df1 = df1.loc[:, ~df1.columns.duplicated()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVhfuub0q69b",
        "outputId": "c944e9d3-9a2a-4203-836c-42ddbd45bb49"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas del DataFrame stations_pretty:\n",
            "Index(['name', 'country', 'region', 'latitude', 'longitude', 'elevation'], dtype='object')\n",
            "\n",
            "Columnas del DataFrame df1:\n",
            "Index(['index', 'time', 'tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun'], dtype='object')\n",
            "\n",
            "Columnas del DataFrame hourly_dataframe:\n",
            "Index(['date', 'temperature_2m', 'date_only'], dtype='object')\n",
            "\n",
            "Columnas del DataFrame daily_avg_temperature:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente se unen los dos dataframes para imputar los valroes faltantes, los cuales en su mayoría se encuentran en 1972, por esta razón se decidió usar"
      ],
      "metadata": {
        "id": "gfx5dctwA0Fe"
      }
    },
    {
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Asegurar que 'time' sea datetime en ambos DataFrames\n",
        "df1['time'] = pd.to_datetime(df1['time'])\n",
        "daily_avg_temperature['time'] = pd.to_datetime(daily_avg_temperature['time'])\n",
        "\n",
        "# Hacer merge de df1 y daily_avg_temperature por 'time'\n",
        "merged_df = pd.merge(df1, daily_avg_temperature, on='time', how='left')\n",
        "\n",
        "# Rellenar los NaN de 'tavg' con los valores de 'avg_temperature_2m'\n",
        "merged_df['tavg'] = merged_df['tavg'].fillna(merged_df['avg_temperature_2m'])\n",
        "\n",
        "# Eliminar la columna auxiliar 'avg_temperature_2m'\n",
        "merged_df = merged_df.drop(columns=['avg_temperature_2m'])\n",
        "\n",
        "# Resultado final\n",
        "df1 = merged_df\n",
        "df1.to_csv('temperaturas_final.csv', index=False)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WMybwqe7rmza"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}
